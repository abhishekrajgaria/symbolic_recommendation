{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e380ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/numpy-1.22.3-py3.10-linux-x86_64.egg (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/networkx-2.8.6-py3.10.egg (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/Jinja2-3.0.3-py3.10.egg (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/MarkupSafe-2.1.1-py3.10-linux-x86_64.egg (from jinja2->torch) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4412b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d996ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b9f5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/user_history_full_data.json\" \n",
    "frequent_bought_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/frequent_pairs_data.json\"\n",
    "product_dict_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/product_dictionary.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(user_history_filepath, 'r')\n",
    "user_history = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "f_json_file = open(frequent_bought_filepath, 'r')\n",
    "frequent_bought = json.load(f_json_file)\n",
    "f_json_file.close()\n",
    "\n",
    "p_json_file = open(product_dict_filepath, 'r')\n",
    "product_dictionary = json.load(p_json_file)\n",
    "p_json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea11ba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'set'>, {'B0BQV3785S': {'B0C3WX29HS', 'B07C2HRMRF', 'B0BFHP8JPG', 'B0BWS6X4WF', 'B0C68XP6K8', 'B09YYZTK1W', 'B07XM9DX9H', 'B0BMQ3G124', 'B09KLYL2ZX', 'B0C54J5D2B', 'B08K41XMBJ', 'B0B63QBWFQ'}, 'B0C54J5D2B': {'B0BQV3785S', 'B0BFHP8JPG', 'B0C3F1KFPR', 'B09YYZTK1W', 'B0BY8YWJWG', 'B0BMQ3G124', 'B09KLYL2ZX', 'B0C3WX29HS', 'B0BX6HYYQ2'}, 'B09KLYL2ZX': {'B0BQV3785S', 'B07C2HRMRF', 'B0C614K38T', 'B0C3F1KFPR', 'B09YYZTK1W', 'B07XM9DX9H', 'B0BMQ3G124', 'B0BXX7LB93', 'B0C54J5D2B', 'B0C3WX29HS', 'B0B63QBWFQ'}, 'B0C68XP6K8': {'B0C3F1KFPR', 'B0BQV3785S'}, 'B0BKV9ZGLH': {'B0CDX5J8C6', 'B09K4SCPYT', 'B0C59SYPNT', 'B0BWS6X4WF', 'B0C6MZ7GVW', 'B07TSG87YD', 'B07XM9DX9H', 'B00OQCZAVW', 'B00ECHYTBI', 'B0C3RDQCL4'}, 'B0C59SYPNT': {'B0BB84JXS9', 'B084SZ4BQB', 'B09K4SCPYT', 'B07L5FC123', 'B0B953DKMY', 'B0C9V7CB9S', 'B0C7XCXYHC', 'B0C75PQQXN', 'B0BN714TVL', 'B07XM9DX9H', 'B07SP24DL5', 'B00OQCZAVW', 'B000BNCA4K', 'B09S8PT9L6', 'B0BKV9ZGLH', 'B0C3RDQCL4', 'B006VB29D8'}, 'B09YYZTK1W': {'B0BQV3785S', 'B0BXX7LB93', 'B07XM9DX9H', 'B0BMQ3G124', 'B09KLYL2ZX', 'B0C54J5D2B', 'B0C3WX29HS', 'B0B63QBWFQ'}, 'B0BMQ3G124': {'B0BQV3785S', 'B0BFHP8JPG', 'B09YYZTK1W', 'B07XM9DX9H', 'B09KLYL2ZX', 'B0C54J5D2B', 'B0B63QBWFQ'}, 'B07XM9DX9H': {'B07CBCQ5P6', 'B0C3BVC21S', 'B09JB8ZP3W', 'B09LHM1FCF', 'B07TX2KNCT', 'B07PXV2688', 'B0BQV3785S', 'B000IDSLOG', 'B006Z2BZBU', 'B01KPWN2XE', 'B0C1TF7MT7', 'B08SWT2CZX', 'B00DDMJ454', 'B0BFHP8JPG', 'B0C5S9H6LQ', 'B09RTBP5T5', 'B0BN714TVL', 'B00ECHYTBI', 'B0052QYLUM', 'B08PZFHK22', 'B09KVRXMHQ', 'B09YYZTK1W', 'B004AHMCKA', 'B09GVN6PY8', 'B00DGN24DY', 'B0BSYZ94VS', 'B0B5JP4MGX', 'B07H4G9XJL', 'B0C3LV4FVT', 'B00OQCZAVW', 'B0092Q01CU', 'B07HM9KG71', 'B0BKV9ZGLH', 'B0C3RDQCL4', 'B00DDMITQ4', 'B09S8PT9L6', 'B0BX4L1Y7B', 'B0C66LKVB9', 'B082G3RGWW', 'B0C6MZ7GVW', 'B09KLYL2ZX', 'B004GTMSG0', 'B0BB84JXS9', 'B0BQ6YS1Q4', 'B07C2HRMRF', 'B0094DJ3XO', 'B0B2CBQGSS', 'B0C9V7CB9S', 'B0C3F1KFPR', 'B07SP24DL5', 'B0C7YWZPFS', 'B002FKE4UU', 'B09F75TWP4', 'B07TSG87YD', 'B00LSUK6MS', 'B0B95XYML6', 'B077TPC9Y7', 'B00DGN23UI', 'B07FK63PSH', 'B009R27JJC', 'B01BOGG5KM', 'B07L5FC123', 'B07RRDX26B', 'B00DDMIWIO', 'B007KXO998', 'B0BG6JYNQX', 'B0C7XCXYHC', 'B08258LZ7M', 'B0C3H3TMMT', 'B000BNCA4K', 'B0B5C37XLQ', 'B00ZV2DQ8K', 'B0CDX5J8C6', 'B00DFFT5HG', 'B00M4M2W1W', 'B0BGYRXM3S', 'B00DDMIMP2', 'B0C59SYPNT', 'B0BB3K2X2G', 'B09PRJGZV4', 'B0081ZOV06', 'B0BMQ3G124', 'B010ECZM24', 'B006VB29D8', 'B0C6P3X28P', 'B0BM5NFFF3', 'B0B6Q19FDY', 'B00Q65V72S', 'B079QDX9F9', 'B0C3FG4HSV', 'B09NB7M1C7', 'B088JL5QJQ'}, 'B0BXX7LB93': {'B0BFHP8JPG', 'B0BXX7KG9F', 'B09YYZTK1W', 'B09KLYL2ZX', 'B0B63QBWFQ'}, 'B0C3LV4FVT': {'B07PXV2688', 'B01DQID0N6', 'B0BSX3RXNV', 'B07TSG87YD', 'B0BM5NFFF3', 'B016IDCAMI', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B09S8PT9L6'}, 'B0BM5NFFF3': {'B0BQ6YS1Q4', 'B00OQCZAVW', 'B00ECHYTBI', 'B0BSYZ94VS', 'B010ECZM24', 'B0C5S9H6LQ', 'B07L5FC123', 'B07TSG87YD', 'B0C7XCXYHC', 'B0BN714TVL', 'B0C3LV4FVT', 'B07SP24DL5', 'B0BG6JYNQX', 'B07XM9DX9H', 'B09LHM1FCF', 'B000BNCA4K', 'B09S8PT9L6', 'B006VB29D8'}, 'B0CDX5J8C6': {'B07FK63PSH', 'B07PXV2688', 'B0BB84JXS9', 'B000IDSLOG', 'B0BSYZ94VS', 'B0C4W7L1S6', 'B07L5FC123', 'B0C6MZ7GVW', 'B07TSG87YD', 'B07XM9DX9H', 'B007A2ZSZ8', 'B0BG6JYNQX', 'B010ECZM24', 'B00OQCZAVW', 'B00ECHYTBI', 'B0BKV9ZGLH', 'B0C3RDQCL4'}, 'B09RTBP5T5': {'B00OQCZAVW', 'B0BB84JXS9', 'B07XM9DX9H'}, 'B0052QYLUM': {'B07XM9DX9H'}, 'B0C4W7L1S6': {'B0C66LKVB9', 'B0CDX5J8C6', 'B0C6MZ7GVW', 'B0C7XCXYHC', 'B00OQCZAVW', 'B00ECHYTBI', 'B09S8PT9L6'}, 'B09KVRXMHQ': {'B0BGYRXM3S', 'B09S8PT9L6', 'B07XM9DX9H'}, 'B0BGYRXM3S': {'B09KVRXMHQ', 'B0BFHP8JPG', 'B07TSG87YD', 'B0B6Q19FDY', 'B07XM9DX9H', 'B09S8PT9L6'}, 'B004JU0H6O': {'B0B2CBQGSS', 'B0C1TK2V65'}, 'B0C1TK2V65': {'B0BBW5RH53', 'B004JU0H6O'}, 'B0C3RDQCL4': {'B00OQCZAVW', 'B09K4SCPYT', 'B0CDX5J8C6', 'B0C59SYPNT', 'B07L5FC123', 'B07TSG87YD', 'B0C9V7CB9S', 'B0C3H3TMMT', 'B0C7XCXYHC', 'B0BN714TVL', 'B07XM9DX9H', 'B007A2ZSZ8', 'B0BG6JYNQX', 'B010ECZM24', 'B004AHMCKA', 'B00ECHYTBI', 'B09S8PT9L6', 'B0BKV9ZGLH'}, 'B084SZ4BQB': {'B0C59SYPNT'}, 'B0BY8YWJWG': {'B0C54J5D2B', 'B0C6BVZHT4'}, 'B0C6BVZHT4': {'B0BY8YWJWG'}, 'B0B63QBWFQ': {'B0BQV3785S', 'B0BFHP8JPG', 'B07TSG87YD', 'B09YYZTK1W', 'B0BXX7LB93', 'B09KLYL2ZX', 'B0BMQ3G124', 'B0C3WX29HS'}, 'B0C3WX29HS': {'B0BQV3785S', 'B0BXX7KG9F', 'B09YYZTK1W', 'B09KLYL2ZX', 'B0C54J5D2B', 'B0B63QBWFQ'}, 'B08K41XMBJ': {'B0BQV3785S', 'B07TSG87YD', 'B0C7SB4412'}, 'B0BN714TVL': {'B0BB84JXS9', 'B0B2CBQGSS', 'B09TLQH4S4', 'B0C9V7CB9S', 'B0C3F1KFPR', 'B0B72F1F7B', 'B004AHMCKA', 'B09LHM1FCF', 'B000IDSLOG', 'B0C59SYPNT', 'B01KPWN2XE', 'B001ET5U2E', 'B07TSG87YD', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B0C3RDQCL4', 'B006VB29D8', 'B00PTL7CSS', 'B0C5S9H6LQ', 'B0BM5NFFF3', 'B0C5B1WSGJ', 'B0716Z3KW3', 'B09S8PT9L6', 'B07QD7PLWG', 'B079QDX9F9', 'B0C7XCXYHC', 'B0C3H3TMMT', 'B000BNCA4K'}, 'B0B2CBQGSS': {'B09S8PT9L6', 'B0BN714TVL', 'B07XM9DX9H', 'B004JU0H6O'}, 'B07TSG87YD': {'B0BB84JXS9', 'B07C2HRMRF', 'B0CDX5J8C6', 'B00HB0WGAY', 'B00HB0WGL8', 'B0C3F1KFPR', 'B0CGM6X71Z', 'B00U0MIDNE', 'B00M4M2W1W', 'B08ZM22VF6', 'B0BGYRXM3S', 'B0B63QBWFQ', 'B07PXV2688', 'B0BF15DVPK', 'B0BWS6X4WF', 'B0C3LV4FVT', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B00HB0WGF4', 'B0BKV9ZGLH', 'B0C3RDQCL4', 'B01BOGG5KM', 'B0BFHP8JPG', 'B0BM5NFFF3', 'B0C9R9WP93', 'B0BN714TVL', 'B0BG6JYNQX', 'B00ECHYTBI', 'B09S8PT9L6', 'B01BOGG4I0', 'B079QDX9F9', 'B0C7XCXYHC', 'B00HG699OO', 'B08K41XMBJ'}, 'B0BG6JYNQX': {'B0BB84JXS9', 'B0CDX5J8C6', 'B001OC5UNK', 'B007A2ZSZ8', 'B0002JETPQ', 'B07TSG87YD', 'B0C5JMRGRD', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B0C3RDQCL4', 'B07L5FC123', 'B0BM5NFFF3', 'B00ECHYTBI', 'B09S8PT9L6', 'B08PZFHK22', 'B0C6MZ7GVW', 'B0C7XCXYHC', 'B08258LZ7M', 'B0BW7CVB9K'}, 'B0BSYZ94VS': {'B0CDX5J8C6', 'B0BV4S59QV', 'B07L5FC123', 'B0BM5NFFF3', 'B0CGM6X71Z', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW'}, 'B07L5FC123': {'B0BB84JXS9', 'B00ECHYTBI', 'B0BSYZ94VS', 'B09K4SCPYT', 'B0CDX5J8C6', 'B0C59SYPNT', 'B0C6MZ7GVW', 'B0BM5NFFF3', 'B004AHMCKA', 'B07XM9DX9H', 'B0BG6JYNQX', 'B010ECZM24', 'B00OQCZAVW', 'B000BNCA4K', 'B0C3RDQCL4'}, 'B0C9V7CB9S': {'B0BB84JXS9', 'B000IDSLOG', 'B0C59SYPNT', 'B0C7XCXYHC', 'B0BN714TVL', 'B07XM9DX9H', 'B07SP24DL5', 'B010ECZM24', 'B00OQCZAVW', 'B000BNCA4K', 'B0C3RDQCL4', 'B006VB29D8'}, 'B006VB29D8': {'B0BB84JXS9', 'B000IDSLOG', 'B0C59SYPNT', 'B079QDX9F9', 'B0C9V7CB9S', 'B0BM5NFFF3', 'B0C87BNJYM', 'B0BN714TVL', 'B07SP24DL5', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B000BNCA4K'}, 'B004GTMSG0': {'B01NC0T9JC', 'B0BB84JXS9', 'B098NNCPHK', 'B001PRCJRO', 'B00ECHYTBI', 'B0C5S9H6LQ', 'B0C6MZ7GVW', 'B07CBCQ5P6', 'B07XM9DX9H', 'B00OQCZAVW', 'B000BNCA4K', 'B09S8PT9L6'}, 'B01NC0T9JC': {'B004GTMSG0', 'B077TPC9Y7'}, 'B08258LZ7M': {'B0BB84JXS9', 'B07XM9DX9H', 'B007A2ZSZ8', 'B0BG6JYNQX', 'B010ECZM24'}, 'B010ECZM24': {'B0BB84JXS9', 'B0CDX5J8C6', 'B0C9V7CB9S', 'B007A2ZSZ8', 'B0B5F7WLL8', 'B0BSYZ94VS', 'B07TSG87YD', 'B0C3LV4FVT', 'B07XM9DX9H', 'B00OQCZAVW', 'B0C3RDQCL4', 'B006VB29D8', 'B07L5FC123', 'B0BM5NFFF3', 'B0BN714TVL', 'B0BG6JYNQX', 'B09S8PT9L6', 'B0C7XCXYHC', 'B08258LZ7M', 'B000BNCA4K'}, 'B09NB7M1C7': {'B082G3RGWW', 'B09S8PT9L6', 'B07XM9DX9H', 'B010S7VZI0'}, 'B010S7VZI0': {'B0C6F57S5V', 'B09NB7M1C7'}, 'B0C66M5TNT': {'B00OQCZAVW', 'B00ECHYTBI'}, 'B00OQCZAVW': {'B004GTMSG0', 'B0BB84JXS9', 'B0BQ6YS1Q4', 'B0CDJZ6GR9', 'B000V88HJM', 'B0CDX5J8C6', 'B09TLQH4S4', 'B0BD887ZH1', 'B07CBCQ5P6', 'B0C9V7CB9S', 'B0C3F1KFPR', 'B0BR7X2DHT', 'B0B953DKMY', 'B007A2ZSZ8', 'B07SP24DL5', 'B09JB8ZP3W', 'B00M4M2W1W', 'B004AHMCKA', 'B09GVN6PY8', 'B07TX2KNCT', 'B09LHM1FCF', 'B007Y4T1G4', 'B07PXV2688', 'B0B9278KY1', 'B09B8LCT53', 'B000IDSLOG', 'B0BSYZ94VS', 'B0C59SYPNT', 'B01KPWN2XE', 'B001ET5U2E', 'B07TSG87YD', 'B011EVXIIE', 'B0B95XYML6', 'B000066665', 'B0C1TF7MT7', 'B0081ZOV06', 'B07XM9DX9H', 'B0C3LV4FVT', 'B0BB3K2X2G', 'B088JL5QJQ', 'B010ECZM24', 'B0092Q01CU', 'B07HM9KG71', 'B0BKV9ZGLH', 'B0C3RDQCL4', 'B006VB29D8', 'B07FK63PSH', 'B0C5S9H6LQ', 'B0C4W7L1S6', 'B09RTBP5T5', 'B07L5FC123', 'B08WBJSYKH', 'B0BM5NFFF3', 'B0B6Q19FDY', 'B0BN714TVL', 'B079ZRG4D2', 'B0BG6JYNQX', 'B00ECHYTBI', 'B09S8PT9L6', 'B09BC2LJJD', 'B0C66LKVB9', 'B000CSBP3G', 'B079QDX9F9', 'B0C6MZ7GVW', 'B0C3FG4HSV', 'B0C7XCXYHC', 'B0C3H3TMMT', 'B0BW5KRPSX', 'B0C66M5TNT', 'B000BNCA4K', 'B0B5C37XLQ'}, 'B079QDX9F9': {'B00ECHYTBI', 'B09TLQH4S4', 'B0BD887ZH1', 'B07TSG87YD', 'B0C7XCXYHC', 'B004AHMCKA', 'B0B95XYML6', 'B0BN714TVL', 'B07XM9DX9H', 'B0B72F1F7B', 'B00OQCZAVW', 'B000BNCA4K', 'B006VB29D8'}, 'B000BNCA4K': {'B004GTMSG0', 'B0BB84JXS9', 'B09TLQH4S4', 'B0BD887ZH1', 'B0B953DKMY', 'B0C9V7CB9S', 'B0B72F1F7B', 'B07SP24DL5', 'B004AHMCKA', 'B000IDSLOG', 'B0C59SYPNT', 'B09MRKFG46', 'B0C1TF7MT7', 'B0BB3K2X2G', 'B0B95XYML6', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B0092Q01CU', 'B006VB29D8', 'B0C5S9H6LQ', 'B07L5FC123', 'B0BM5NFFF3', 'B0BN714TVL', 'B00ECHYTBI', 'B09S8PT9L6', 'B079QDX9F9', 'B0C7XCXYHC', 'B0C3H3TMMT'}, 'B0BB84JXS9': {'B004GTMSG0', 'B0CDX5J8C6', 'B0C9V7CB9S', 'B07SP24DL5', 'B004AHMCKA', 'B07PXV2688', 'B000IDSLOG', 'B0C59SYPNT', 'B07TSG87YD', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B006VB29D8', 'B0C5S9H6LQ', 'B09RTBP5T5', 'B07L5FC123', 'B0BN714TVL', 'B0BG6JYNQX', 'B08258LZ7M', 'B000BNCA4K', 'B0B5C37XLQ'}, 'B009R27JJC': {'B07XM9DX9H'}, 'B00DDMITQ4': {'B07XM9DX9H'}, 'B0CGM6X71Z': {'B07TSG87YD', 'B0BSYZ94VS'}, 'B007A2ZSZ8': {'B0CDX5J8C6', 'B004ECJWK4', 'B08258LZ7M', 'B0BG6JYNQX', 'B010ECZM24', 'B00OQCZAVW', 'B09S8PT9L6', 'B0C3RDQCL4', 'B00068O22S'}, 'B00068O22S': {'B007A2ZSZ8'}, 'B004ECJWK4': {'B007A2ZSZ8'}, 'B09S8PT9L6': {'B004GTMSG0', 'B0045VA3SO', 'B09QQLPSY2', 'B07C2HRMRF', 'B0B2CBQGSS', 'B07N8Y2H4J', 'B0C3F1KFPR', 'B007A2ZSZ8', 'B09JB8ZP3W', 'B09LHM1FCF', 'B0BGYRXM3S', 'B000IDSLOG', 'B0BVQN55GB', 'B0C59SYPNT', 'B01KPWN2XE', 'B07TSG87YD', 'B08D7HKYY4', 'B0B95XYML6', 'B0C3LV4FVT', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B0C3RDQCL4', 'B0C6P3X28P', 'B0C4W7L1S6', 'B0BM5NFFF3', 'B0B6Q19FDY', 'B0BN714TVL', 'B0BG6JYNQX', 'B00ECHYTBI', 'B09KVRXMHQ', 'B0948G4LMS', 'B082G3RGWW', 'B09NB7M1C7', 'B0C7XCXYHC', 'B000BNCA4K', 'B0B5C37XLQ'}, 'B07PXV2688': {'B0BB84JXS9', 'B00HB0WGF4', 'B0BFHP8JPG', 'B0CDX5J8C6', 'B0C6MZ7GVW', 'B07TSG87YD', 'B0C3F1KFPR', 'B07XM9DX9H', 'B0C3LV4FVT', 'B00M4M2W1W', 'B00OQCZAVW', 'B00ECHYTBI'}, 'B0BW5KRPSX': {'B00OQCZAVW'}, 'B004AHMCKA': {'B0BB84JXS9', 'B000IDSLOG', 'B0C5S9H6LQ', 'B07L5FC123', 'B0BD887ZH1', 'B079QDX9F9', 'B0BN714TVL', 'B07XM9DX9H', 'B00OQCZAVW', 'B000BNCA4K', 'B0C3RDQCL4'}, 'B000IDSLOG': {'B0BB84JXS9', 'B00OQCZAVW', 'B0CDX5J8C6', 'B0C9V7CB9S', 'B0B95XYML6', 'B0BN714TVL', 'B07XM9DX9H', 'B004AHMCKA', 'B000BNCA4K', 'B09S8PT9L6', 'B006VB29D8'}, 'B07CBCQ5P6': {'B004GTMSG0', 'B00OQCZAVW', 'B00ECHYTBI', 'B07XM9DX9H'}, 'B0BFHP8JPG': {'B01EKZO93O', 'B07PXV2688', 'B0BQV3785S', 'B0BWS6X4WF', 'B07TSG87YD', 'B0C54J5D2B', 'B09Y7L9KBW', 'B0BXX7LB93', 'B07XM9DX9H', 'B0BMQ3G124', 'B08ZM22VF6', 'B0BGYRXM3S', 'B0B63QBWFQ'}, 'B0B953DKMY': {'B00OQCZAVW', 'B0B9278KY1', 'B000BNCA4K', 'B0C59SYPNT'}, 'B0BSX3RXNV': {'B01DQID0N6', 'B07F3Q518C', 'B0C3LV4FVT', 'B0B5F7WLL8'}, 'B07C2HRMRF': {'B0BQV3785S', 'B0BWS6X4WF', 'B07TSG87YD', 'B0C3F1KFPR', 'B07XM9DX9H', 'B09KLYL2ZX', 'B08ZM22VF6', 'B09S8PT9L6'}, 'B07N8Y2H4J': {'B08YFD73P8', 'B09S8PT9L6'}, 'B0C9R9WP93': {'B07TSG87YD'}, 'B088JL5QJQ': {'B00OQCZAVW', 'B07XM9DX9H'}, 'B00M4M2W1W': {'B07PXV2688', 'B00OQCZAVW', 'B07XM9DX9H', 'B07TSG87YD'}, 'B0B5F7WLL8': {'B010ECZM24', 'B07F3Q518C', 'B0BSX3RXNV'}, 'B08ZM22VF6': {'B0BFHP8JPG', 'B0BWS6X4WF', 'B07TSG87YD', 'B07C2HRMRF'}, 'B0BWS6X4WF': {'B0BQV3785S', 'B07C2HRMRF', 'B0BFHP8JPG', 'B07TSG87YD', 'B08ZM22VF6', 'B0BKV9ZGLH'}, 'B0C5S9H6LQ': {'B004GTMSG0', 'B0BB84JXS9', 'B00OQCZAVW', 'B00ECHYTBI', 'B0BM5NFFF3', 'B0BN714TVL', 'B07XM9DX9H', 'B004AHMCKA', 'B000BNCA4K'}, 'B0B7D9TGZD': {'B08XMJZ65Z'}, 'B08XMJZ65Z': {'B0B7D9TGZD'}, 'B082G3RGWW': {'B09NB7M1C7', 'B09S8PT9L6', 'B07XM9DX9H'}, 'B00B9ZHQ5W': {'B0C3FG4HSV'}, 'B0C3FG4HSV': {'B00OQCZAVW', 'B07XM9DX9H', 'B00B9ZHQ5W', 'B00B9ZHQAC'}, 'B0C2BJKGMH': {'B0BYRQGWTM', 'B0C2BKG5LJ'}, 'B0BYRQGWTM': {'B0C2BJKGMH', 'B0C2BKG5LJ'}, 'B0BXX7KG9F': {'B0C3WX29HS', 'B0BXX7LB93'}, 'B0C7XCXYHC': {'B0C9V7CB9S', 'B0C3F1KFPR', 'B0006BAJN6', 'B0C59SYPNT', 'B07TSG87YD', 'B07XM9DX9H', 'B010ECZM24', 'B00OQCZAVW', 'B09VP2FQ2G', 'B0C3RDQCL4', 'B0C4W7L1S6', 'B0BM5NFFF3', 'B0B6Q19FDY', 'B0BN714TVL', 'B0BG6JYNQX', 'B00ECHYTBI', 'B09S8PT9L6', 'B0C66LKVB9', 'B079QDX9F9', 'B000BNCA4K', 'B0B5C37XLQ'}, 'B01DQID0N6': {'B0BSX3RXNV', 'B0C3LV4FVT'}, 'B0B72F1F7B': {'B079QDX9F9', 'B000BNCA4K', 'B0BN714TVL'}, 'B0BD887ZH1': {'B004AHMCKA', 'B000BNCA4K', 'B00OQCZAVW', 'B079QDX9F9'}, 'B0C2BKG5LJ': {'B0C2BJKGMH', 'B0BYRQGWTM'}, 'B09TLQH4S4': {'B00OQCZAVW', 'B000BNCA4K', 'B079QDX9F9', 'B0BN714TVL'}, 'B0C6MZ7GVW': {'B004GTMSG0', 'B07PXV2688', 'B0CDX5J8C6', 'B0C4W7L1S6', 'B07L5FC123', 'B07XM9DX9H', 'B0BG6JYNQX', 'B00OQCZAVW', 'B00ECHYTBI', 'B0BKV9ZGLH'}, 'B08L59R7QN': {'B011EVXIIE'}, 'B011EVXIIE': {'B00OQCZAVW', 'B08L59R7QN'}, 'B0C66LKVB9': {'B0C4W7L1S6', 'B0C7XCXYHC', 'B07XM9DX9H', 'B0C3H3TMMT', 'B00OQCZAVW'}, 'B0C3H3TMMT': {'B0C66LKVB9', 'B00ECHYTBI', 'B0BN714TVL', 'B07XM9DX9H', 'B00OQCZAVW', 'B000BNCA4K', 'B0C3RDQCL4'}, 'B00ECHYTBI': {'B004GTMSG0', 'B0CDJZ6GR9', 'B0CDX5J8C6', 'B0BZJNGJS9', 'B07CBCQ5P6', 'B09JB8ZP3W', 'B09GVN6PY8', 'B07PXV2688', 'B0BTTSCPH9', 'B00ECI1JM4', 'B075ZNQ5X5', 'B01KPWN2XE', 'B07TSG87YD', 'B0C69T6N4H', 'B0C1TF7MT7', 'B07XM9DX9H', 'B00OQCZAVW', 'B0092Q01CU', 'B0BKV9ZGLH', 'B0C3RDQCL4', 'B00ECH5ARA', 'B0C5S9H6LQ', 'B0C4W7L1S6', 'B07L5FC123', 'B0009RNXNA', 'B0BM5NFFF3', 'B00HZFJQ12', 'B079ZRG4D2', 'B0BG6JYNQX', 'B09S8PT9L6', 'B00MRZIGWA', 'B079QDX9F9', 'B0C6MZ7GVW', 'B0C7XCXYHC', 'B09XY1DGHW', 'B0C3H3TMMT', 'B0C66M5TNT', 'B000BNCA4K', 'B0BJWL7Y8Y', 'B0B5C37XLQ'}, 'B07F3Q518C': {'B0BSX3RXNV', 'B0B5F7WLL8'}, 'B0B6Q19FDY': {'B003KMWATY', 'B0C7XCXYHC', 'B07XM9DX9H', 'B00OQCZAVW', 'B0BGYRXM3S', 'B09S8PT9L6'}, 'B01KPWN2XE': {'B0BN714TVL', 'B07XM9DX9H', 'B00OQCZAVW', 'B00ECHYTBI', 'B09S8PT9L6', 'B0B5C37XLQ'}, 'B001ET5U2E': {'B00OQCZAVW', 'B0BN714TVL'}, 'B09K4SCPYT': {'B0C59SYPNT', 'B07L5FC123', 'B0BKV9ZGLH', 'B0C3RDQCL4'}, 'B01BOGG5KM': {'B07XM9DX9H', 'B07TSG87YD'}, 'B00HB0WGAY': {'B07TSG87YD'}, 'B0C3F1KFPR': {'B07PXV2688', 'B07C2HRMRF', 'B0C68XP6K8', 'B07TSG87YD', 'B0C7XCXYHC', 'B00HG699OO', 'B0BN714TVL', 'B07XM9DX9H', 'B09KLYL2ZX', 'B0C54J5D2B', 'B00OQCZAVW', 'B09S8PT9L6'}, 'B07SP24DL5': {'B0B9278KY1', 'B0BB84JXS9', 'B0C59SYPNT', 'B004QZBEFK', 'B0C9V7CB9S', 'B0BM5NFFF3', 'B07XM9DX9H', 'B00OQCZAVW', 'B000BNCA4K', 'B006VB29D8'}, 'B0BB3K2X2G': {'B00OQCZAVW', 'B000BNCA4K', 'B07XM9DX9H'}, 'B077TPC9Y7': {'B01NC0T9JC', 'B07XM9DX9H'}, 'B01EKZO93O': {'B0BFHP8JPG'}, 'B00DDMIWIO': {'B07XM9DX9H'}, 'B0C3BVC21S': {'B07XM9DX9H'}, 'B07TX2KNCT': {'B00OQCZAVW', 'B07XM9DX9H'}, 'B09HNWV9LY': {'B0B38NVCC5'}, 'B0B38NVCC5': {'B09SC1ZWXZ', 'B09HNWV9LY'}, 'B0C5JMRGRD': {'B0BG6JYNQX'}, 'B0092Q01CU': {'B00OQCZAVW', 'B00ECHYTBI', 'B07XM9DX9H', 'B000BNCA4K'}, 'B001OC5UNK': {'B0BG6JYNQX'}, 'B0B5JP4MGX': {'B07XM9DX9H'}, 'B0081ZOV06': {'B00OQCZAVW', 'B07XM9DX9H'}, 'B09BC2LJJD': {'B00OQCZAVW'}, 'B00HB0WGF4': {'B07PXV2688', 'B07TSG87YD'}, 'B0BQ6YS1Q4': {'B00OQCZAVW', 'B07XM9DX9H', 'B0BM5NFFF3'}, 'B00DGN23UI': {'B07XM9DX9H'}, 'B007KXO998': {'B07XM9DX9H'}, 'B079ZRG4D2': {'B00OQCZAVW', 'B00ECHYTBI'}, 'B09MRKFG46': {'B000BNCA4K', 'B09MVH241X'}, 'B07FK63PSH': {'B00OQCZAVW', 'B07XM9DX9H', 'B0CDX5J8C6'}, 'B07W6JGWD9': {'B09DMNN5NQ'}, 'B09DMNN5NQ': {'B07W6JGWD9'}, 'B000066665': {'B00OQCZAVW'}, 'B0B95XYML6': {'B000IDSLOG', 'B079QDX9F9', 'B07XM9DX9H', 'B00OQCZAVW', 'B000BNCA4K', 'B09S8PT9L6'}, 'B09JB8ZP3W': {'B00OQCZAVW', 'B00ECHYTBI', 'B09S8PT9L6', 'B07XM9DX9H'}, 'B0BF15DVPK': {'B07TSG87YD'}, 'B0CDJZ6GR9': {'B00OQCZAVW', 'B00ECHYTBI', 'B00OO9K5QM', 'B07CRQMSDZ'}, 'B0C1TF7MT7': {'B00OQCZAVW', 'B00ECHYTBI', 'B07XM9DX9H', 'B000BNCA4K'}, 'B0C7YWZPFS': {'B07XM9DX9H'}, 'B0B5C37XLQ': {'B0BB84JXS9', 'B0948G4LMS', 'B01KPWN2XE', 'B0C7XCXYHC', 'B07XM9DX9H', 'B00OQCZAVW', 'B00ECHYTBI', 'B09S8PT9L6'}, 'B00DDMIMP2': {'B07XM9DX9H'}, 'B00ECI1JM4': {'B00ECHYTBI'}, 'B0C87BNJYM': {'B006VB29D8'}, 'B0BX4L1Y7B': {'B00OKJGLI2', 'B07XM9DX9H'}, 'B00OKJGLI2': {'B0BX4L1Y7B'}, 'B00OO9K5QM': {'B0CDJZ6GR9'}, 'B003KMWATY': {'B0B6Q19FDY'}, 'B0BV4S59QV': {'B0BSYZ94VS'}, 'B016IDCAMI': {'B0C3LV4FVT'}, 'B07RRDX26B': {'B07XM9DX9H'}, 'B0BVQN55GB': {'B06X9MWL79', 'B09S8PT9L6'}, 'B099KYPW57': {'B07CZ2BBNQ'}, 'B07CZ2BBNQ': {'B099KYPW57'}, 'B002FKE4UU': {'B07XM9DX9H'}, 'B0B9278KY1': {'B00AWLZFTS', 'B0B953DKMY', 'B0C6B3MC2N', 'B07SP24DL5', 'B00OQCZAVW', 'B00MRZIGWA'}, 'B0C6P3X28P': {'B09S8PT9L6', 'B07XM9DX9H'}, 'B09GVN6PY8': {'B00OQCZAVW', 'B00ECHYTBI', 'B07XM9DX9H'}, 'B07HM9KG71': {'B00OQCZAVW', 'B07XM9DX9H'}, 'B0BX6HYYQ2': {'B0C54J5D2B'}, 'B0C614K38T': {'B09KLYL2ZX'}, 'B007Y4T1G4': {'B00OQCZAVW', 'B0C6BLLQ6R'}, 'B00ECH5ARA': {'B00ECHYTBI'}, 'B00B9ZHQAC': {'B0C3FG4HSV'}, 'B08WBJSYKH': {'B00OQCZAVW', 'B0C5LWNGH8'}, 'B0C5B1WSGJ': {'B0BN714TVL'}, 'B00HZFJQ12': {'B00ECHYTBI'}, 'B09LHM1FCF': {'B08SWT2CZX', 'B0BM5NFFF3', 'B0BN714TVL', 'B07XM9DX9H', 'B00OQCZAVW', 'B09S8PT9L6'}, 'B074XF5J51': {'B074XQD4L2'}, 'B074XQD4L2': {'B074XF5J51'}, 'B0009RNXNA': {'B00ECHYTBI'}, 'B07TFL8ZNR': {'B0BVJP4W3B', 'B0B78D5WP8', 'B07NRCL9YF'}, 'B07NRCL9YF': {'B07TFL8ZNR'}, 'B0B78D5WP8': {'B07TFL8ZNR'}, 'B0BVJP4W3B': {'B07TFL8ZNR'}, 'B01BOGG4I0': {'B07TSG87YD'}, 'B00DGN24DY': {'B07XM9DX9H'}, 'B07H4G9XJL': {'B07XM9DX9H'}, 'B0045VA3SO': {'B09S8PT9L6'}, 'B08D7HKYY4': {'B09S8PT9L6'}, 'B00DDMJ454': {'B07XM9DX9H'}, 'B00PTL7CSS': {'B0BN714TVL'}, 'B096LMNPYX': {'B08JHZYFCF'}, 'B08JHZYFCF': {'B096LMNPYX'}, 'B09XY1DGHW': {'B00ECHYTBI'}, 'B00U0MIDNE': {'B07TSG87YD'}, 'B0BYNZ65W2': {'B09TWJYVH7'}, 'B09TWJYVH7': {'B0BYNZ65W2'}, 'B0094DJ3XO': {'B07XM9DX9H'}, 'B00ZV2DQ8K': {'B07XM9DX9H'}, 'B005UND06I': {'B07K1W7WN5'}, 'B07K1W7WN5': {'B005UND06I'}, 'B09PRJGZV4': {'B07XM9DX9H'}, 'B000V88HJM': {'B00OQCZAVW'}, 'B0948G4LMS': {'B09S8PT9L6', 'B0B5C37XLQ'}, 'B08PZFHK22': {'B07XM9DX9H', 'B0BG6JYNQX'}, 'B0C75PQQXN': {'B0C59SYPNT'}, 'B0BFYZ13CJ': {'B09M4RW5N8'}, 'B09M4RW5N8': {'B0BFYZ13CJ'}, 'B0BW7CVB9K': {'B0BG6JYNQX'}, 'B09B8LCT53': {'B00OQCZAVW'}, 'B0BBW5RH53': {'B09JJG2LD4', 'B0C1TK2V65'}, 'B09JJG2LD4': {'B0BBW5RH53'}, 'B00LSUK6MS': {'B07XM9DX9H', 'B00DDMJ332'}, 'B00HG699OO': {'B0C3F1KFPR', 'B07TSG87YD'}, 'B000CSBP3G': {'B00OQCZAVW'}, 'B09F75TWP4': {'B07XM9DX9H'}, 'B0006BAJN6': {'B0C7XCXYHC'}, 'B07QD7PLWG': {'B0BN714TVL'}, 'B09SC1ZWXZ': {'B0B38NVCC5'}, 'B0716Z3KW3': {'B0BN714TVL'}, 'B006Z2BZBU': {'B09J29BDD3', 'B07XM9DX9H'}, 'B09J29BDD3': {'B006Z2BZBU'}, 'B0BTTSCPH9': {'B00ECHYTBI'}, 'B00HB0WGL8': {'B07TSG87YD'}, 'B07CRQMSDZ': {'B0CDJZ6GR9'}, 'B09Y7L9KBW': {'B0BFHP8JPG'}, 'B09VP2FQ2G': {'B0C7XCXYHC'}, 'B00MRZIGWA': {'B0C6B3MC2N', 'B0B9278KY1', 'B00ECHYTBI', 'B00AWLZFTS'}, 'B06X9MWL79': {'B0BVQN55GB'}, 'B00Q65V72S': {'B07XM9DX9H'}, 'B0C7SB4412': {'B08K41XMBJ'}, 'B0C6B3MC2N': {'B0B9278KY1', 'B00MRZIGWA', 'B00AWLZFTS'}, 'B0BZJNGJS9': {'B00ECHYTBI'}, 'B07MS6C7WV': {'B0C3L2BB4L'}, 'B0C3L2BB4L': {'B07MS6C7WV'}, 'B08SWT2CZX': {'B09LHM1FCF', 'B07XM9DX9H'}, 'B00DDMJ332': {'B00LSUK6MS'}, 'B00DFFT5HG': {'B07XM9DX9H'}, 'B0BQ8RZYTR': {'B0BXRLF25X'}, 'B0BXRLF25X': {'B0BTTGLDCR', 'B07WHH1PLJ', 'B0BQ8RZYTR'}, 'B09QQLPSY2': {'B09S8PT9L6'}, 'B0C5LWNGH8': {'B08WBJSYKH'}, 'B0BJWL7Y8Y': {'B00ECHYTBI'}, 'B0C69T6N4H': {'B00ECHYTBI'}, 'B00AWLZFTS': {'B0C6B3MC2N', 'B0B9278KY1', 'B00MRZIGWA'}, 'B0C6BLLQ6R': {'B007Y4T1G4'}, 'B0BR7X2DHT': {'B00OQCZAVW'}, 'B09JDJPLMH': {'B07CJ3ZGJS'}, 'B07CJ3ZGJS': {'B09JDJPLMH'}, 'B004QZBEFK': {'B07SP24DL5'}, 'B08716VNTG': {'B08716GMGC'}, 'B08716GMGC': {'B08716VNTG'}, 'B0BVQC1NGY': {'B07T4VVNT8'}, 'B07T4VVNT8': {'B0BVQC1NGY'}, 'B09MVH241X': {'B09MRKFG46'}, 'B00483GAJU': {'B09TGTDRMR'}, 'B09TGTDRMR': {'B00483GAJU'}, 'B08BQHKQTZ': {'B001B1FHIC'}, 'B001B1FHIC': {'B08BQHKQTZ'}, 'B00PZVF068': {'B0C22M8G1L', 'B0C1PYV2SV', 'B01BTTML98'}, 'B01BTTML98': {'B0C22M8G1L', 'B0C1PYV2SV', 'B00PZVF068'}, 'B09TV5H6Q5': {'B07SCX9MB7', 'B005G3QSF2'}, 'B005G3QSF2': {'B09TV5H6Q5', 'B07SCX9MB7'}, 'B019RC73GK': {'B0081C9UPA'}, 'B0081C9UPA': {'B019RC73GK'}, 'B07968TQPC': {'B0B6HBP55N', 'B0973XW53T'}, 'B0B6HBP55N': {'B0973XW53T', 'B07968TQPC'}, 'B0BTTGLDCR': {'B07WHH1PLJ', 'B0BXRLF25X'}, 'B01M1KI7ZR': {'B07J5DS8SN'}, 'B07J5DS8SN': {'B01M1DSSSX', 'B01M1KI7ZR', 'B08C1CNQWJ'}, 'B08C1CNQWJ': {'B07J5DS8SN'}, 'B01M1DSSSX': {'B07J5DS8SN'}, 'B0002JETPQ': {'B0BG6JYNQX'}, 'B07SCX9MB7': {'B09TV5H6Q5', 'B005G3QSF2'}, 'B00UVW3PSQ': {'B005RD6RN4', 'B00XYVEA2Q'}, 'B005RD6RN4': {'B00UVW3PSQ', 'B00XYVEA2Q'}, 'B00XYVEA2Q': {'B005RD6RN4', 'B00UVW3PSQ'}, 'B09C7SXGJ6': {'B08XQG4K3W', 'B08F3LHPYL'}, 'B08F3LHPYL': {'B08XQG4K3W', 'B09C7SXGJ6'}, 'B08XQG4K3W': {'B08F3LHPYL', 'B09C7SXGJ6'}, 'B00VKJDUC0': {'B001GCVKAA', 'B08MZ1D69D'}, 'B001GCVKAA': {'B00VKJDUC0', 'B08MZ1D69D'}, 'B08MZ1D69D': {'B00VKJDUC0', 'B001GCVKAA'}, 'B00BRHSCLE': {'B09TVDBNQZ'}, 'B09TVDBNQZ': {'B00BRHSCLE'}, 'B00CE8C7NE': {'B000F1OQ8Q'}, 'B000F1OQ8Q': {'B00CE8C7NE'}, 'B0C6F57S5V': {'B010S7VZI0'}, 'B07WHH1PLJ': {'B0BTTGLDCR', 'B0BXRLF25X'}, 'B09B32RTNK': {'B001IDYB4Y'}, 'B001IDYB4Y': {'B09B32RTNK'}, 'B075ZNQ5X5': {'B00ECHYTBI'}, 'B00OFNUUE4': {'B07S7TN28G'}, 'B07S7TN28G': {'B00OFNUUE4'}, 'B0BPFM7JSG': {'B015QYB526'}, 'B015QYB526': {'B0BPFM7JSG'}, 'B0728KRC5K': {'B07NVDGQ3G'}, 'B07NVDGQ3G': {'B0728KRC5K'}, 'B09P7XHVVR': {'B0B4RGKZTJ'}, 'B0B4RGKZTJ': {'B09P7XHVVR'}, 'B0BXVXDG5M': {'B01A59VMOI'}, 'B01A59VMOI': {'B0BXVXDG5M'}, 'B0C1G651QP': {'B08XNGJ97L'}, 'B08XNGJ97L': {'B0C1G651QP'}, 'B0C1PYV2SV': {'B0C22M8G1L', 'B00PZVF068', 'B01BTTML98'}, 'B0C22M8G1L': {'B00PZVF068', 'B0C1PYV2SV', 'B01BTTML98'}, 'B004I110D8': {'B008J4FHZ2'}, 'B008J4FHZ2': {'B004I110D8'}, 'B0C5826WLS': {'B004HO5870'}, 'B004HO5870': {'B0C5826WLS'}, 'B00CWN3HSU': {'B00S143JHS'}, 'B00S143JHS': {'B00CWN3HSU'}, 'B0085V8TU4': {'B08D94541X'}, 'B08D94541X': {'B0085V8TU4'}, 'B00XVASD14': {'B07RK2DBHH', 'B002N64QYA', 'B007B0VFA6'}, 'B007B0VFA6': {'B002N64QYA', 'B07RK2DBHH', 'B00XVASD14'}, 'B002N64QYA': {'B07RK2DBHH', 'B007B0VFA6', 'B00XVASD14'}, 'B07RK2DBHH': {'B002N64QYA', 'B007B0VFA6', 'B00XVASD14'}, 'B0C7QJ1M3V': {'B0BJH834JQ'}, 'B0BJH834JQ': {'B0C7QJ1M3V'}, 'B07SV4VCKV': {'B08B18G6PV'}, 'B08B18G6PV': {'B07SV4VCKV'}, 'B007A91H9C': {'B07TFBGQB3'}, 'B07TFBGQB3': {'B007A91H9C'}, 'B01MSPKD0N': {'B0BW14DYXG'}, 'B0BW14DYXG': {'B01MSPKD0N'}, 'B08DSVHVYN': {'B07F3TWSJR'}, 'B07F3TWSJR': {'B08DSVHVYN'}, 'B0BV1XZCNH': {'B00KKCLHS2'}, 'B00KKCLHS2': {'B0BV1XZCNH'}, 'B01MTAM3SX': {'B07VHK9SLG'}, 'B07VHK9SLG': {'B01MTAM3SX'}, 'B09KNXV95P': {'B0B94RLRBT'}, 'B0B94RLRBT': {'B09KNXV95P'}, 'B00126LXNO': {'B09RPCRSKY', 'B01MD1L6ZL', 'B07J62T7TH'}, 'B09RPCRSKY': {'B00126LXNO', 'B01MD1L6ZL', 'B07J62T7TH'}, 'B07J62T7TH': {'B09RPCRSKY', 'B00126LXNO', 'B01MD1L6ZL'}, 'B01MD1L6ZL': {'B09RPCRSKY', 'B00126LXNO', 'B07J62T7TH'}, 'B0938KYXDY': {'B01AQHNPLW'}, 'B01AQHNPLW': {'B0938KYXDY'}, 'B0973XW53T': {'B0B6HBP55N', 'B07968TQPC'}, 'B09VQ2QNGV': {'B08PBMY7H4'}, 'B08PBMY7H4': {'B09VQ2QNGV'}, 'B0BKPRJMQP': {'B0B5FL9HJZ'}, 'B0B5FL9HJZ': {'B0BKPRJMQP'}, 'B00RYQ32EE': {'B0081C9UOQ'}, 'B0081C9UOQ': {'B00RYQ32EE'}, 'B0C9LYNH2P': {'B06XTT17QC'}, 'B06XTT17QC': {'B0C9LYNH2P'}, 'B01BM29FWS': {'B01HG7NKPG', 'B004KT82AM'}, 'B004KT82AM': {'B01BM29FWS', 'B01HG7NKPG'}, 'B01HG7NKPG': {'B01BM29FWS', 'B004KT82AM'}, 'B0007CS4EU': {'B00TH47OQI'}, 'B00TH47OQI': {'B0007CS4EU'}, 'B00EBRAJEK': {'B00G3XRDSA', 'B00E8KJYNC'}, 'B00E8KJYNC': {'B00EBRAJEK', 'B00G3XRDSA'}, 'B00G3XRDSA': {'B00EBRAJEK', 'B00E8KJYNC'}, 'B01N29O25I': {'B0050K6DUQ'}, 'B0050K6DUQ': {'B01N29O25I'}, 'B073XNKMPH': {'B08VDT3RY4'}, 'B08VDT3RY4': {'B073XNKMPH'}, 'B0CDWXP168': {'B09V2Q444H'}, 'B09V2Q444H': {'B0CDWXP168'}, 'B07VRBYXSR': {'B092CPCXM4'}, 'B092CPCXM4': {'B07VRBYXSR'}, 'B016S5QI9C': {'B0BYTS3XG4'}, 'B0BYTS3XG4': {'B016S5QI9C'}, 'B0C2FM7CPZ': {'B08BNBR79G'}, 'B08BNBR79G': {'B0C2FM7CPZ'}, 'B08GCK3JN5': {'B09C4S4ML6', 'B09C4TB476'}, 'B09C4S4ML6': {'B09C4TB476', 'B08GCK3JN5'}, 'B09C4TB476': {'B09C4S4ML6', 'B08GCK3JN5'}, 'B07TYL19F8': {'B0BW2TC8D2', 'B08RSSKNT7', 'B097QJ27F6'}, 'B0BW2TC8D2': {'B07TYL19F8', 'B08RSSKNT7', 'B097QJ27F6'}, 'B08RSSKNT7': {'B0BW2TC8D2', 'B07TYL19F8', 'B097QJ27F6'}, 'B097QJ27F6': {'B0BW2TC8D2', 'B07TYL19F8', 'B08RSSKNT7'}, 'B0BTBSS5DZ': {'B07P9V6GX3'}, 'B07P9V6GX3': {'B0BTBSS5DZ'}, 'B000PRUAFI': {'B000E1BL9Y'}, 'B000E1BL9Y': {'B000PRUAFI'}, 'B0777BY1SX': {'B00S1NNXHK'}, 'B00S1NNXHK': {'B0777BY1SX'}, 'B0BYK248VJ': {'B0912HHD4C'}, 'B0912HHD4C': {'B0BYK248VJ'}, 'B08H22JLBV': {'B09K4QKX6M', 'B01CCFJBV4'}, 'B09K4QKX6M': {'B08H22JLBV', 'B01CCFJBV4'}, 'B01CCFJBV4': {'B09K4QKX6M', 'B08H22JLBV'}, 'B08JTH4KPK': {'B09ST2F43Q'}, 'B09ST2F43Q': {'B08JTH4KPK'}, 'B01DNP7YZW': {'B01EC0FHVK'}, 'B01EC0FHVK': {'B01DNP7YZW'}, 'B08YFD73P8': {'B07N8Y2H4J'}, 'B00GD0Z204': {'B075M3WDST'}, 'B075M3WDST': {'B00GD0Z204'}, 'B001PRCJRO': {'B004GTMSG0', 'B098NNCPHK'}, 'B098NNCPHK': {'B004GTMSG0', 'B001PRCJRO'}, 'B08GM6GCM8': {'B07X8M7GG8'}, 'B07X8M7GG8': {'B08GM6GCM8'}, 'B08HJBL2MX': {'B0854829WC'}, 'B0854829WC': {'B08HJBL2MX'}, 'B0007KPC6U': {'B002850D0M'}, 'B002850D0M': {'B0007KPC6U'}, 'B08HYCNQ33': {'B0BVM2TQV4'}, 'B0BVM2TQV4': {'B08HYCNQ33'}, 'B08KWMCMYJ': {'B0BZ557LDM'}, 'B0BZ557LDM': {'B08KWMCMYJ'}, 'B014D4H75E': {'B0B95H9KKT'}, 'B0B95H9KKT': {'B014D4H75E'}, 'B07G999XHB': {'B00IWOZZZQ'}, 'B00IWOZZZQ': {'B07G999XHB'}, 'B06XHNGQQ6': {'B01E7XC0AS', 'B0BVTQXCQK', 'B0BJ18PXRZ'}, 'B0BVTQXCQK': {'B01E7XC0AS', 'B06XHNGQQ6', 'B0BJ18PXRZ'}, 'B01E7XC0AS': {'B0BVTQXCQK', 'B06XHNGQQ6', 'B0BJ18PXRZ'}, 'B0BJ18PXRZ': {'B01E7XC0AS', 'B0BVTQXCQK', 'B06XHNGQQ6'}, 'B017XSFH7M': {'B01EF11XJQ'}, 'B01EF11XJQ': {'B017XSFH7M'}, 'B09ST897ZL': {'B09S5P6HSL'}, 'B09S5P6HSL': {'B09ST897ZL'}, 'B07MTM6GHN': {'B07V4NJ38S'}, 'B07V4NJ38S': {'B07MTM6GHN'}, 'B0B53YVWT6': {'B07QLKFV3P', 'B07YHXW1G1', 'B08ZLKG4J1'}, 'B07QLKFV3P': {'B08ZLKG4J1', 'B07YHXW1G1', 'B0B53YVWT6'}, 'B07YHXW1G1': {'B07QLKFV3P', 'B08ZLKG4J1', 'B0B53YVWT6'}, 'B08ZLKG4J1': {'B07QLKFV3P', 'B07YHXW1G1', 'B0B53YVWT6'}, 'B001CDFPY0': {'B00BJHX4FG', 'B005FYO7H8'}, 'B005FYO7H8': {'B001CDFPY0', 'B00BJHX4FG'}, 'B00BJHX4FG': {'B001CDFPY0', 'B005FYO7H8'}, 'B001PO5FWI': {'B008P8EZOG'}, 'B008P8EZOG': {'B001PO5FWI'}, 'B00UXFBLRS': {'B01LZHASKW'}, 'B01LZHASKW': {'B00UXFBLRS'}, 'B00HS3X82E': {'B00O3L8PUE'}, 'B00O3L8PUE': {'B00HS3X82E'}, 'B0BPM9QBBV': {'B008J2MZL8'}, 'B008J2MZL8': {'B0BPM9QBBV'}, 'B07BF5W4MF': {'B0BHW32D46'}, 'B0BHW32D46': {'B07BF5W4MF'}, 'B000WEHO76': {'B007R0PUI8'}, 'B007R0PUI8': {'B000WEHO76'}, 'B00QW2BMH0': {'B01JAVRN72'}, 'B01JAVRN72': {'B00QW2BMH0'}, 'B07SPH7B85': {'B002UYSHMM'}, 'B002UYSHMM': {'B07SPH7B85'}, 'B0C9F1F7SC': {'B078SMKSLL'}, 'B078SMKSLL': {'B0C9F1F7SC'}, 'B004XLDCM0': {'B00IPPUPG6'}, 'B00IPPUPG6': {'B004XLDCM0'}, 'B07B9N9S1C': {'B07JZG7HPJ'}, 'B07JZG7HPJ': {'B07B9N9S1C'}, 'B07LG8QYFW': {'B07TT21PJ4'}, 'B07TT21PJ4': {'B07LG8QYFW'}, 'B00YD3O330': {'B01G4T47S6'}, 'B01G4T47S6': {'B00YD3O330'}, 'B082WH315T': {'B0C5XCY6CX'}, 'B0C5XCY6CX': {'B082WH315T'}, 'B01LZXI9TE': {'B015OOVX3E'}, 'B015OOVX3E': {'B01LZXI9TE'}, 'B07WTXWC32': {'B07SJJTQ92'}, 'B07SJJTQ92': {'B07WTXWC32'}, 'B0C3D4P1VS': {'B0995G57LK'}, 'B0995G57LK': {'B0C3D4P1VS'}, 'B07JQTW7NF': {'B079SMGDPB'}, 'B079SMGDPB': {'B07JQTW7NF'}, 'B07786Z3V1': {'B09DDFHKZ7'}, 'B09DDFHKZ7': {'B07786Z3V1'}, 'B07GYQLCW1': {'B07S2JDHT3'}, 'B07S2JDHT3': {'B07GYQLCW1'}, 'B004IA4180': {'B07KJJVPWG'}, 'B07KJJVPWG': {'B004IA4180'}, 'B00AUDAE4O': {'B08291FNP5'}, 'B08291FNP5': {'B00AUDAE4O'}, 'B004H3XRDI': {'B00DUGIO36'}, 'B00DUGIO36': {'B004H3XRDI'}, 'B07B4HDWBH': {'B075ZXNKTV'}, 'B075ZXNKTV': {'B07B4HDWBH'}, 'B072WH1FY1': {'B016NXBRTK'}, 'B016NXBRTK': {'B072WH1FY1'}, 'B09Q98PGBX': {'B099D3WZSD'}, 'B099D3WZSD': {'B09Q98PGBX'}, 'B0BRXLQ414': {'B0BZ7KW9NX'}, 'B0BZ7KW9NX': {'B0BRXLQ414'}, 'B0BT8Q25WC': {'B01N5SVHUU'}, 'B01N5SVHUU': {'B0BT8Q25WC'}, 'B0B2KYC3SN': {'B0848R6CV1'}, 'B0848R6CV1': {'B0B2KYC3SN'}})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def parse_frequent_bought(frequent_bought):\n",
    "    \"\"\"\n",
    "    Parse the frequent bought pairs into a product-to-products dictionary.\n",
    "    Args:\n",
    "        frequent_bought (dict): Original frequent bought pairs with frequencies.\n",
    "    Returns:\n",
    "        product_to_frequent (dict): Dictionary mapping each product ID to a set of frequently bought products.\n",
    "    \"\"\"\n",
    "    product_to_frequent = defaultdict(set)\n",
    "\n",
    "    for pair, frequency in frequent_bought.items():\n",
    "        # Split the product pair into individual product IDs\n",
    "        product1, product2 = pair.split(',')\n",
    "        # Add each product to the other's set\n",
    "        product_to_frequent[product1].add(product2)\n",
    "        product_to_frequent[product2].add(product1)\n",
    "\n",
    "    return product_to_frequent\n",
    "\n",
    "product_to_frequent = parse_frequent_bought(frequent_bought)\n",
    "print(product_to_frequent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f6be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_with_history_sizes(user_h):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for user_id in user_history.keys():\n",
    "        cnt_dict[len(user_history[user_id])]+=1\n",
    "    print(cnt_dict)\n",
    "    \n",
    "def count_user_with_history_size_above(user_h, above):\n",
    "    cnt = 0\n",
    "    for user_id in user_history.keys():\n",
    "        if len(user_history[user_id]) >= above:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\n",
    "def filter_users(user_h, min_history_length, max_history_length=-1)->dict:\n",
    "    filtered_users = {}\n",
    "    count=0\n",
    "    for user, history in user_h.items():\n",
    "        if len(history) >= min_history_length:\n",
    "            filtered_users[user] = history[:max_history_length]\n",
    "            count+=1\n",
    "        \n",
    "        if count==-1:\n",
    "            break\n",
    "    return filtered_users\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5f7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297\n"
     ]
    }
   ],
   "source": [
    "filtered_users = filter_users(user_history, 20, 50)\n",
    "print(len(filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9263e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177b8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d33587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 4669, Validation users: 1168, Test users: 1460\n"
     ]
    }
   ],
   "source": [
    "users = list(filtered_users.keys())\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train users into train (80%) and validation (20%) within the training set\n",
    "train_users, val_users = train_test_split(train_users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train, validation, and test data dictionaries\n",
    "train_data = {user: filtered_users[user] for user in train_users}\n",
    "val_data = {user: filtered_users[user] for user in val_users}\n",
    "test_data = {user: filtered_users[user] for user in test_users}\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train users: {len(train_users)}, Validation users: {len(val_users)}, Test users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "main_category_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2939bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_categories = [entry[\"main_category\"] for user in user_history.keys() for entry in user_history[user]]\n",
    "main_category_encoder.fit(main_categories)\n",
    "categories = [entry[\"categories\"] for user in user_history.keys() for entry in user_history[user]]\n",
    "category_encoder.fit(categories)\n",
    "product_ids = [entry[\"product_id\"] for user in user_history.keys() for entry in user_history[user]]\n",
    "product_encoder.fit(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad48488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(histories):\n",
    "    all_ratings = [h[\"rating\"] for user in histories for h in histories[user]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit([[r] for r in all_ratings])\n",
    "    return scaler\n",
    "\n",
    "rating_scaler = normalize_ratings(filtered_users)\n",
    "\n",
    "def preprocess_history(history):\n",
    "    texts = [\n",
    "        f\"{h.get('review_title','')} {h.get('features','')} {h.get('main_category')}\" for h in history\n",
    "    ]\n",
    "    \n",
    "    texts = [text for text in texts if text.strip()]\n",
    "    \n",
    "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    ratings = torch.tensor([rating_scaler.transform([[h[\"rating\"]]])[0][0] for h in history], dtype=torch.float32)\n",
    "    \n",
    "    #categories = torch.tensor(category_encoder.transform([h[\"main_category\"] for h in history]))\n",
    "    \n",
    "    categories = torch.tensor(category_encoder.transform([h[\"categories\"] for h in history]))\n",
    "    \n",
    "    product_ids = torch.tensor(product_encoder.transform([h[\"product_id\"] for h in history]))\n",
    "    \n",
    "    return tokens, ratings, categories, product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c45703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, category_encoder, product_encoder, product_to_frequent, is_train=False, seq_len=15, pred_len=5):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.category_encoder = category_encoder # Is it required?\n",
    "        self.product_encoder = product_encoder # Is it required?\n",
    "        self.product_to_frequent = product_to_frequent\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.is_train = is_train\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, history = list(self.data.items())[idx]\n",
    "        tokens, ratings, categories, product_ids = preprocess_history(history)\n",
    "        input_tokens = {\n",
    "            \"input_ids\":tokens[\"input_ids\"][:self.seq_len],\n",
    "            \"attention_mask\": tokens[\"attention_mask\"][:self.seq_len],\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"][:self.seq_len],\n",
    "        }\n",
    "        input_ratings = ratings[:self.seq_len]\n",
    "        input_categories = categories[:self.seq_len]\n",
    "        \n",
    "        future_products = product_ids[self.seq_len:]\n",
    "        target_vector = torch.zeros(len(self.product_encoder.classes_))\n",
    "        target_vector[future_products] = 1\n",
    "        \n",
    "        if self.is_train:\n",
    "            for product_id in product_ids[:self.seq_len]:\n",
    "                frequent_set = self.product_to_frequent.get(self.product_encoder.classes_[product_id.item()], set())\n",
    "#                 print(frequent_set)\n",
    "                encoded_frequent_products = self.product_encoder.transform(list(frequent_set))\n",
    "                target_vector[encoded_frequent_products]=1\n",
    "                \n",
    "        \n",
    "        return input_tokens, input_ratings, input_categories, target_vector\n",
    "\n",
    "train_dataset = UserDataset(train_data, tokenizer, category_encoder, product_encoder, product_to_frequent, is_train=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c5d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleVectorTransformerRecommendationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_categories=900, num_products=1000, d_model=128, nhead=8, num_encoder_layers=3):\n",
    "        super(SingleVectorTransformerRecommendationModel, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        self.category_embedding = nn.Embedding(num_categories, d_model)\n",
    "        \n",
    "        self.history_encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.history_encoder = nn.TransformerEncoder(self.history_encoder_layer, num_layers = num_encoder_layers)\n",
    "        \n",
    "        self.input_projection = nn.Linear(bert_hidden_size + d_model, d_model)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, num_products)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.activation = nn.GELU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, tokens, ratings, categories):\n",
    "        batch_size, seq_len, max_token_length = tokens[\"input_ids\"].shape\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"].view(-1, max_token_length)\n",
    "        attention_mask = tokens[\"attention_mask\"].view(-1, max_token_length)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].view(-1, max_token_length)\n",
    "        \n",
    "        bert_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "        \n",
    "        sequence_output = sequence_output[:,0,:].view(batch_size, seq_len, -1)\n",
    "        \n",
    "        category_embeds = self.category_embedding(categories)\n",
    "        combined_features = torch.cat([sequence_output, category_embeds], dim=-1)\n",
    "        \n",
    "        projected_features = self.input_projection(combined_features)  # Shape: [batch_size, seq_len, d_model]\n",
    "        normalized_features = self.layer_norm(projected_features)\n",
    "        activated_features = self.activation(normalized_features) \n",
    "\n",
    "        # Encode history with Transformer\n",
    "        history_encoded = self.history_encoder(activated_features)\n",
    "        \n",
    "        \n",
    "#         history_encoded = self.history_encoder(combined_features)\n",
    "        aggregated_features = history_encoded.mean(dim=1)\n",
    "        aggregated_features = self.layer_norm(aggregated_features)\n",
    "        \n",
    "        \n",
    "        logits = self.fc_out(aggregated_features)\n",
    "        probabilities = self.sigmoid(logits)\n",
    "        \n",
    "        return probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ef75dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute Top-K accuracy for multi-label classification.\n",
    "    Args:\n",
    "        predicted_vector (Tensor): Predicted probabilities for products [batch_size, num_products].\n",
    "        target_vector (Tensor): Binary target vector [batch_size, num_products].\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        top_k_accuracy (float): Top-K accuracy for the batch.\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch\n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "    # Gather the target values corresponding to the top-k predictions\n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "    # Count how many of the top-k predictions are correct\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Compute the accuracy as the mean of correct predictions\n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "\n",
    "    return top_k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "99cd5b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_metrics(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute top-k accuracy and precision for classification tasks.\n",
    "    \n",
    "    Args:\n",
    "        predicted_vector (torch.Tensor): Predicted probabilities or logits\n",
    "        target_vector (torch.Tensor): Ground truth labels\n",
    "        k (int, optional): Number of top predictions to consider. Defaults to 5.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing top-k accuracy and precision\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch \n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k] \n",
    " \n",
    "    # Gather the target values corresponding to the top-k predictions \n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k] \n",
    " \n",
    "    # Compute top-k accuracy\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size] \n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "    \n",
    "    # Compute top-k precision\n",
    "    # Precision = (number of correct predictions in top-k) / (total number of top-k predictions)\n",
    "    correct_predictions_count = true_positives.sum()\n",
    "    top_k_precision = correct_predictions_count / (top_k_preds.shape[0] * k)\n",
    "    \n",
    "    return top_k_accuracy,top_k_precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "475befa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_top_k_precision = 0.0\n",
    "    \n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            ratings = ratings.to(device)\n",
    "            categories = categories.to(device)\n",
    "            target_vector = target_vector.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc, top_k_prec= compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "\n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_top_k_precision += top_k_prec\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc,\n",
    "                                     \"Batch Top-K prec\": top_k_prec})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "    average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "    average_top_k_precision = total_top_k_precision / total_batches\n",
    "    print(f\"Average Top-{k} Precision: {average_top_k_precision:.4f}\")\n",
    "    return average_top_k_accuracy\n",
    "\n",
    "# Example usage:\n",
    "# average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "val_dataset = UserDataset(val_data, tokenizer, category_encoder, product_encoder, product_to_frequent)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d59fa52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleVectorTransformerRecommendationModel(num_categories=len(category_encoder.classes_), num_products=len(product_encoder.classes_)).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8e52db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|| 584/584 [29:24<00:00,  3.02s/it, Loss=0.693]\n",
      "Evaluating: 100%|| 292/292 [03:20<00:00,  1.46it/s, Batch Top-K Acc=0]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1122\n",
      "Epoch 1 Val result top k acc 0.11215753424657535\n",
      "Epoch 1/3, Average Loss: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|| 584/584 [28:26<00:00,  2.92s/it, Loss=0.693]\n",
      "Evaluating: 100%|| 292/292 [03:20<00:00,  1.46it/s, Batch Top-K Acc=0]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1122\n",
      "Epoch 2 Val result top k acc 0.11215753424657535\n",
      "Epoch 2/3, Average Loss: 0.6932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   0%|          | 1/584 [00:06<1:00:36,  6.24s/it, Loss=0.693]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/u1471428/2598669/ipykernel_1852087/1494158597.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Update progress bar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
    "\n",
    "    for tokens, ratings, categories, target_vector in progress_bar:\n",
    "        tokens = {key: val.to(device) for key, val in tokens.items()}\n",
    "        ratings = ratings.to(device)\n",
    "        categories = categories.to(device)\n",
    "        target_vector = target_vector.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_vector, target_vector.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "    \n",
    "    average_top_k = evaluate_top_k_accuracy(model, val_loader, k=5)\n",
    "    print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944899d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1332cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'single_vector_data_augmented.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"single_vector_data_augmented.pth\")\n",
    "print(\"Model's state dictionary saved to 'single_vector_data_augmented.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb3eb891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_201366/1839281486.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"single_vector_data_augmented.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"single_vector_data_augmented.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "68c597a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder, product_to_frequent)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34080e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 1460/1460 [04:16<00:00,  5.69it/s, Batch Top-K Acc=0, Batch Top-K prec=0]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1185\n",
      "Average Top-5 Precision: 0.0263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 1460/1460 [04:16<00:00,  5.69it/s, Batch Top-K Acc=0, Batch Top-K prec=0]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-3 Accuracy: 0.0781\n",
      "Average Top-3 Precision: 0.0276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|| 1460/1460 [04:16<00:00,  5.69it/s, Batch Top-K Acc=0, Batch Top-K prec=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.0397\n",
      "Average Top-1 Precision: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=3)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=1)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "36a23bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ana_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            ratings = ratings.to(device)\n",
    "            categories = categories.to(device)\n",
    "            target_vector = target_vector.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc, top_k_prec = compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "            \n",
    "            top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "            # Gather the target values corresponding to the top-k predictions\n",
    "            true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "            # Count how many of the top-k predictions are correct\n",
    "            top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "            # Compute the accuracy as the mean of correct predictions\n",
    "            top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "            \n",
    "            if top_k_accuracy>=0.5:\n",
    "                print(top_k_correct.float().item())\n",
    "                to_print = analyze_predictions_and_targets(top_k_preds, target_vector)\n",
    "                print(json.dumps(to_print, indent=2))\n",
    "                break\n",
    "                \n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "#     average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "#     print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "#     return average_top_k_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06eebe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analyze_predictions_and_targets(top_k_preds, target_vector):\n",
    "    \"\"\"\n",
    "    Analyze predictions to determine which items are in predictions but not in targets,\n",
    "    which are in both predictions and targets, and which are in the target vector.\n",
    "\n",
    "    Args:\n",
    "        top_k_preds (Tensor): Indices of top-K predicted products [batch_size, k].\n",
    "        target_vector (Tensor): Binary target vector for products [batch_size, num_products].\n",
    "        product_encoder (LabelEncoder): Encoder to map product indices to product IDs.\n",
    "        product_dictionary (dict): Dictionary containing product details (title, rating, etc.).\n",
    "\n",
    "    Returns:\n",
    "        result (list of dict): Contains information about items in `top_k_preds` but not in `target_vector`,\n",
    "                               items in both `top_k_preds` and `target_vector`,\n",
    "                               and items in `target_vector`.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    # Convert product indices to product IDs\n",
    "    product_indices = torch.arange(target_vector.size(-1))  # [num_products]\n",
    "    product_ids = product_encoder.inverse_transform(product_indices.cpu().numpy())  # Decode all product IDs\n",
    "    \n",
    "    for batch_idx in range(top_k_preds.size(0)):\n",
    "        preds = top_k_preds[batch_idx].cpu().numpy()  # Predicted indices\n",
    "        targets = torch.where(target_vector[batch_idx] > 0)[0].cpu().numpy()  # Target indices\n",
    "        \n",
    "        preds_product_ids = [product_ids[i] for i in preds]  # Get product IDs for predictions\n",
    "        targets_product_ids = [product_ids[i] for i in targets]  # Get product IDs for targets\n",
    "        \n",
    "        # Products in predictions but not in targets\n",
    "        preds_not_in_targets = list(set(preds_product_ids) - set(targets_product_ids))\n",
    "        \n",
    "        # Products in both predictions and targets\n",
    "        preds_in_targets = list(set(preds_product_ids) & set(targets_product_ids))\n",
    "        \n",
    "        # Products only in the target vector\n",
    "        target_only = list(set(targets_product_ids))\n",
    "        \n",
    "        # Fetch details from the product dictionary\n",
    "        items_not_in_targets = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in preds_not_in_targets\n",
    "        ]\n",
    "        \n",
    "        items_in_targets = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in preds_in_targets\n",
    "        ]\n",
    "        \n",
    "        items_in_target_vector = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in target_only\n",
    "        ]\n",
    "        \n",
    "        result.append(\n",
    "            {\n",
    "                \"batch_index\": batch_idx,\n",
    "                \"not_in_targets\": items_not_in_targets,\n",
    "                \"in_targets\": items_in_targets,\n",
    "                \"in_target_vector\": items_in_target_vector,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_results_as_json(results):\n",
    "    \"\"\"\n",
    "    Print results in JSON format with indent=2.\n",
    "    Args:\n",
    "        results (list of dict): The result of analyze_predictions_and_targets.\n",
    "    \"\"\"\n",
    "    print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92d62b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder, product_to_frequent)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "011deca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 2/1460 [00:00<05:50,  4.16it/s, Batch Top-K Acc=1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"batch_index\": 0,\n",
      "    \"not_in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B07TSG87YD\",\n",
      "        \"title\": \"HUGGIES Snug & Dry Diapers, Size 5, 96 Count, GIGA JR PACK (Packaging May Vary)\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07XM9DX9H\",\n",
      "        \"title\": \"Diapers Newborn/Size 1 (8-14 lb), 84 Count - Pampers Swaddlers Sensitive Disposable Baby Diapers, Super Pack\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00OQCZAVW\",\n",
      "        \"title\": \"Baby Banana Yellow Banana Infant Toothbrush, Easy to Hold, Made in the USA, Train Infants Babies and Toddlers for Oral Hygiene, Teether Effect for Sore Gums, 4.33\\\" x 0.39\\\" x 7.87\\\", BR003\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00ECHYTBI\",\n",
      "        \"title\": \"Infant Optics DXR-8 Video Baby Monitor, Non-WiFi Hack-Proof FHSS Connection, Interchangeable Lenses, Pan Tilt Zoom, LED Sound Bar, Night Vision, and Two-way Talk\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B09S8PT9L6\",\n",
      "        \"title\": \"Summer 4-Sided Changing Pad \\u2013 Durable Quilted Changing Pad Made with Waterproof Material, Includes Infant Safety Belt with Quick-Release Buckle\",\n",
      "        \"rating\": 4.8\n",
      "      }\n",
      "    ],\n",
      "    \"in_targets\": [],\n",
      "    \"in_target_vector\": [\n",
      "      {\n",
      "        \"product_id\": \"B01MPYA11N\",\n",
      "        \"title\": \"Frenchie Mini Couture Baby Infant Hooded Towel Pink Dog,Extra Large 40\\\"X 30\\\"\",\n",
      "        \"rating\": 4.2\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07D9C3197\",\n",
      "        \"title\": \"Evenflo Position and Lock Tall Pressure Mount Wood Gate (Expands From 31- 50 Inches)\",\n",
      "        \"rating\": 4.1\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BFHP8JPG\",\n",
      "        \"title\": \"Luvs Premium Stretch Diapers with Ultra Leakguards Diapers, Size 3, 234 Count\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B075YNKPND\",\n",
      "        \"title\": \"Kyapoo Baby Washcloths Premuim Bamboo Extra Absorbent and Soft for Babies,Newborns, Infants and Toddlers, Perfect for Sensitive Skin Baby Shower Gift 5 Pack\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0B32RR1MV\",\n",
      "        \"title\": \"Mylicon Gas Relief Drops for Infants and Babies, Dye Free Formula, 0.5 Fluid Ounce\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07DGPGR56\",\n",
      "        \"title\": \"Johnson's Sleepy Time Bedtime Baby Gift Set with Relaxing NaturalCalm Aromas, Bedtime Baby Bath Shampoo, Wash & Lotion Essentials, Hypoallergenic & Paraben-Free, 4 Items\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01DWA5Y6O\",\n",
      "        \"title\": \"Wall Decal Personalized Custom Name Decals I'm A Little Princess Minnie Mouse Vinyl Sticker Home Decor Nursery Girl Baby Room Kids Stickers Children's Decor Art Mural SM77\",\n",
      "        \"rating\": 5.0\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07DHY875N\",\n",
      "        \"title\": \"Walnut Tree Baby - Baby Bath Visor, Bath Visor for Toddlers, Adjustable Shower Visor, Multipurpose Baby Bath Hat Shield, Nose, Ears, & Eye Protector for Shower, Peony Pink\",\n",
      "        \"rating\": 3.5\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ana_top_k_accuracy(model, test_loader, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e04db5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   1%|          | 16/1460 [00:03<04:41,  5.12it/s, Batch Top-K Acc=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[\n",
      "  {\n",
      "    \"batch_index\": 0,\n",
      "    \"not_in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B00OQCZAVW\",\n",
      "        \"title\": \"Baby Banana Yellow Banana Infant Toothbrush, Easy to Hold, Made in the USA, Train Infants Babies and Toddlers for Oral Hygiene, Teether Effect for Sore Gums, 4.33\\\" x 0.39\\\" x 7.87\\\", BR003\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00ECHYTBI\",\n",
      "        \"title\": \"Infant Optics DXR-8 Video Baby Monitor, Non-WiFi Hack-Proof FHSS Connection, Interchangeable Lenses, Pan Tilt Zoom, LED Sound Bar, Night Vision, and Two-way Talk\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07XM9DX9H\",\n",
      "        \"title\": \"Diapers Newborn/Size 1 (8-14 lb), 84 Count - Pampers Swaddlers Sensitive Disposable Baby Diapers, Super Pack\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07TSG87YD\",\n",
      "        \"title\": \"HUGGIES Snug & Dry Diapers, Size 5, 96 Count, GIGA JR PACK (Packaging May Vary)\",\n",
      "        \"rating\": 4.6\n",
      "      }\n",
      "    ],\n",
      "    \"in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B09S8PT9L6\",\n",
      "        \"title\": \"Summer 4-Sided Changing Pad \\u2013 Durable Quilted Changing Pad Made with Waterproof Material, Includes Infant Safety Belt with Quick-Release Buckle\",\n",
      "        \"rating\": 4.8\n",
      "      }\n",
      "    ],\n",
      "    \"in_target_vector\": [\n",
      "      {\n",
      "        \"product_id\": \"B096LKKG3C\",\n",
      "        \"title\": \"Summer Pop \\u2018n Play Portable Playard, Green - Lightweight Play Pen for Indoor and Outdoor Use - Portable Playard with Fast, Easy and Compact Fold\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01IAYM6LI\",\n",
      "        \"title\": \"HomeDoReMi Cabinet Lock Safety, m\",\n",
      "        \"rating\": 3.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00XFCJYP2\",\n",
      "        \"title\": \"Baby Bandana Drool Bibs for Drooling and Teething 4 Pack Gift Set\\\"Aztec\\\"by Copper Pearl, Soft Set of Cloth Bandana Bibs for Any Baby Girl or Boy, Cute Registry Ideas for Baby Shower Gifts\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00G3XRB0K\",\n",
      "        \"title\": \"Baby Jogger City Elite Single Stroller, Gray\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00STTR0UC\",\n",
      "        \"title\": \"Fisher-Price Comfort Curve Bouncer: Rainforest Friends\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00O3MBTVU\",\n",
      "        \"title\": \"Plum Organics Baby Hello Morning, Apple, Cinnamon and Quinoa Oatmeal, 3 Ounce\",\n",
      "        \"rating\": 3.3\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01KPWN2XE\",\n",
      "        \"title\": \"Munchkin\\u00ae Waterproof Changing Pad Liners, 6 Count\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07T3HX2YF\",\n",
      "        \"title\": \"RaZ-Berry Baby Spoon/Baby's First Spoon / 100% Silicone\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00E1ABYSC\",\n",
      "        \"title\": \"Britax Car Seat Waterproof Liner - Moisture Wicking Fabric + No Slip Grip + Machine Washable + Crash Tested\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B082PMBSJB\",\n",
      "        \"title\": \"Babo Botanicals Moisturizing Lotion - Face & Body Plant-Based Lotion for Babies, Kids & Adults with Sensitive or Dry Skin - with Colloidal Oatmeal, Organic Calendula & Shea Butter 8 fl.oz.(Pack of 2)\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B08WBJSYKH\",\n",
      "        \"title\": \"Earth Mama Organic Diaper Balm Multipurpose Baby Ointment | EWG Verified, Petroleum & Fragrance Free with Calendula for Sensitive Skin, 2-Fluid Ounce (3-Pack)\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BM5NFFF3\",\n",
      "        \"title\": \"Aquaphor Baby Healing Ointment Advanced Therapy Skin Protectant, Dry Skin and Diaper Rash Ointment, 14 Oz Jar\",\n",
      "        \"rating\": 4.9\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B001AFKZMW\",\n",
      "        \"title\": \"thinkbaby Sippy Cup or Bottle Conversion Kit\",\n",
      "        \"rating\": 4.3\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B09DMNN5NQ\",\n",
      "        \"title\": \"First Essentials by NUK Kiddy Cutlery Spoon Set, color may vary, 3pk\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B079ZRG4D2\",\n",
      "        \"title\": \"Bambo Nature Baby Diapers Classic, Size 4 (15-40 Lbs), 30 Count\",\n",
      "        \"rating\": 4.4\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BG6JYNQX\",\n",
      "        \"title\": \"Regalo Easy Step 38.5-Inch Wide Walk Thru Baby Gate, Includes 6-Inch Extension Kit, Pressure Mount Kit, Wall Cups and Mounting Kit\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B09S8PT9L6\",\n",
      "        \"title\": \"Summer 4-Sided Changing Pad \\u2013 Durable Quilted Changing Pad Made with Waterproof Material, Includes Infant Safety Belt with Quick-Release Buckle\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00913CZWI\",\n",
      "        \"title\": \"Skip Hop Toddler Utensils, Zootensils Fork & Spoon Set, Owl\",\n",
      "        \"rating\": 4.4\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BRY4L35M\",\n",
      "        \"title\": \"Newborn-to-Toddler Bath Center & Shower (Pink)\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01HJF0GO8\",\n",
      "        \"title\": \"Pampers Swaddlers Alcohol & fragrance free Overnights Disposable Baby Diapers, Size 4, 62 Count\",\n",
      "        \"rating\": 4.2\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BSM86F92\",\n",
      "        \"title\": \"Burt's Bees Baby Bibs, Lap-Shoulder Drool Cloths, 100% Organic Cotton with Absorbent Terry Towel Backing\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B094B4H5ZT\",\n",
      "        \"title\": \"Burt's Bees Baby - Blankets, Set of 2, 100% Organic Cotton Swaddle, Stroller, Receiving Blankets (Heather Grey Solid + Honeybee Print) , 29x29 Inch (Pack of 2)\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00SOXK898\",\n",
      "        \"title\": \"BreathableBaby | Best Friend and Blanket\",\n",
      "        \"rating\": 4.2\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0C7XCXYHC\",\n",
      "        \"title\": \"Dr. Brown's Reusable Sponge Baby Bottle Cleaning Brush with Suction Cup Stand, Narrow Scrubber and Nipple Cleaner, Grey 1-Pack\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0C3L2BB4L\",\n",
      "        \"title\": \"Ubbi Diaper Changing Value Set, Odor Locking Modern Design Baby Accessory, Must Have Set Includes Grey Diaper Pail, Diaper Sacks, Odor Absorbing Gel, Travel Changing Mat and Diaper Pail Waste Bags\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00A4B34IA\",\n",
      "        \"title\": \"Fisher-Price Infant-to-Toddler Rocker - Circus Celebration\",\n",
      "        \"rating\": 4.7\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ana_top_k_accuracy(model, test_loader, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89537be3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
