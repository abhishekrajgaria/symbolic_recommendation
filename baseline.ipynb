{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/numpy-1.22.3-py3.10-linux-x86_64.egg (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/networkx-2.8.6-py3.10.egg (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/Jinja2-3.0.3-py3.10.egg (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/MarkupSafe-2.1.1-py3.10-linux-x86_64.egg (from jinja2->torch) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/uufs/chpc.utah.edu/common/home/u1471428/nsl/symbolic_recommendation\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants\n",
    "\n",
    "user_history_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/user_history_data.json\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "json_file = open(user_history_filepath, 'r')\n",
    "user_history = json.load(json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_with_history_sizes(user_h):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for user_id in user_history.keys():\n",
    "        cnt_dict[len(user_history[user_id])]+=1\n",
    "    print(cnt_dict)\n",
    "    \n",
    "def count_user_with_history_size_above(user_h, above):\n",
    "    cnt = 0\n",
    "    for user_id in user_history.keys():\n",
    "        if len(user_history[user_id]) >= above:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\n",
    "def filter_users(user_h, min_history_length, max_history_length=-1)->dict:\n",
    "    filtered_users = {}\n",
    "    count=0\n",
    "    for user, history in user_h.items():\n",
    "        if len(history) >= min_history_length:\n",
    "            filtered_users[user] = history[:min_history_length]\n",
    "            count+=1\n",
    "        \n",
    "        if count==-1:\n",
    "            break\n",
    "    return filtered_users\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297\n"
     ]
    }
   ],
   "source": [
    "# count_user_with_history_sizes(user_history)\n",
    "# count_user_with_history_size_above(user_history, 20)\n",
    "\n",
    "filtered_users = filter_users(user_history, 20)\n",
    "print(len(filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "{'rating': 3.0, 'review_title': \"Didn't work for my needs\", 'review_text': \"Truth be told, I actually got this playpen as I was looking for an alternative to having a crate for the puppy I was getting. I am truly disappointed when I first used it. First, I had a real hard time putting this together. As a single 60 something year old woman, I had to painstakingly, reading instructions, try to put this together by myself. I guess I was hoping I could just open the box and 'pop' open the playpen. Instead, I had to put a load of pipe like pieces together and then string the netting and pace over it. After finally getting it together, I was ready to try the new puppy in there. The puppy was not happy (of course, probably to be expected) and I found her almost able to rip the netting apart. It also did not form the strongest of a surround set up (it was kind of flimsy). My puppy had more fun trying to hide under it when she was outside of it. So, this all being said, I am not sure how it would work with a child. But, to be honest, I probably wouldn't buy it. I am sure a child of anything more than baby size could probably work their way out of it. I\", 'product_id': 'B0BBM75S58', 'timestamp': 1672145450051, 'main_category': 'Baby', 'features': \"âœ¨LARGE PLAYPEN: The 51*51*27inch play yard is spacious enough for 2 toddlers to play at the same time. Large enough space for children to crawl, stand, and play freely, helping babies explore and learn the world, and the 27-inch high fence is perfect for indoor/outdoor play for toddlers from 6 months to 6 years old., âœ¨FREE HANDS: 360Â° full field of view design, in daily life, mothers always have their things to do, so they can't pay attention to the baby all the time, and this giant playpen can turn any place into a safe baby play yard. At the same time, the baby can see you from any side through the mesh around the fence, so the mother can feel at ease., âœ¨SAFETY PLAY YARD: The baby play area frame is connected with a rust-proof alloy tube and ABS joint, which is strong and stable and can bear the weight of adults without bending, the bottom is made of wear-resistant, non-slip special fabric, BPA-free and non-toxic. The fence cloth cover made of thickened sponge covers the edge of the fence. When the baby collides with the fence, it can effectively increase the buffer and reduce the damage., âœ¨INTIMATE DESIGN: The outer zipper door is designed to facilitate interaction with the baby. In addition, a storage bag is added to the outside of the large playpen, which is convenient for placing diapers and other items. Our fence is completely wrapped in soft cloth, there is no risk of exposed gaps and pinches, please use it with confidence!, ðŸ‘¶EASY ASSEMBLY: The simple and sturdy structure is convenient for your assembly and disassembly, it only takes a few minutes without any tools. Breathable, quick-drying fabric, just wipe with a damp cloth and soap to clean. (No padding at the bottom, you need to buy an extra baby play mat)\", 'description': '', 'title': 'Baby Playpen Baby Playard, Playpen for Babies and Toddlers with Gate, 51x51\" Small Baby Fence, Sturdy Safety Playpen, Indoor & Outdoor Kids Activity Center (with Anti-Slip Base)', 'categories': ['Baby Products', 'Nursery', 'Furniture', 'Playards']}\n"
     ]
    }
   ],
   "source": [
    "for user_id in filtered_users.keys():\n",
    "    history = (filtered_users[user_id])\n",
    "    print(len(history))\n",
    "    print(history[0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(len(user) == 20 for user in filtered_users.values()), \"Not all users have a history length of 20\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for user_id, user_data in filtered_users.items():\n",
    "#     history_length = len(user_data)\n",
    "#     print(f\"User {user_id}: History length = {history_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare for Train, Validation and Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test set\n",
    "\n",
    "users = list(filtered_users.keys())\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "train_data = {user: filtered_users[user] for user in train_users}\n",
    "test_data = {user: filtered_users[user] for user in test_users}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer and Label Encoder\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "category_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Encoders\n",
    "\n",
    "categories = [entry[\"categories\"][-1] for user in users for entry in filtered_users[user]]\n",
    "category_encoder.fit(categories)\n",
    "product_ids = [entry[\"product_id\"] for user in users for entry in filtered_users[user]]\n",
    "product_encoder.fit(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(histories):\n",
    "    all_ratings = [h[\"rating\"] for user in histories for h in histories[user]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit([[r] for r in all_ratings])\n",
    "    return scaler\n",
    "\n",
    "rating_scaler = normalize_ratings(filtered_users)\n",
    "\n",
    "def preprocess_history(history):\n",
    "    texts = [\n",
    "        f\"{h.get('review_title','')} {h.get('review_text','')} {h.get('features','')} {h.get('description','')}\" for h in history\n",
    "    ]\n",
    "    \n",
    "    texts = [text for text in texts if text.strip()]\n",
    "    \n",
    "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    ratings = torch.tensor([rating_scaler.transform([[h[\"rating\"]]])[0][0] for h in history], dtype=torch.float32)\n",
    "    \n",
    "    categories = torch.tensor(category_encoder.transform([h[\"categories\"][-1] for h in history]))\n",
    "    \n",
    "    product_ids = torch.tensor(product_encoder.transform([h[\"product_id\"] for h in history]))\n",
    "    \n",
    "    return tokens, ratings, categories, product_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting into tensor OR dataloader\n",
    "\n",
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, category_encoder, product_encoder, seq_len=15, pred_len=5):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.category_encoder = category_encoder # Is it required?\n",
    "        self.product_encoder = product_encoder # Is it required?\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, history = list(self.data.items())[idx]\n",
    "        tokens, ratings, categories, product_ids = preprocess_history(history)\n",
    "        input_tokens = {\n",
    "            \"input_ids\":tokens[\"input_ids\"][:self.seq_len],\n",
    "            \"attention_mask\": tokens[\"attention_mask\"][:self.seq_len],\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"][:self.seq_len],\n",
    "        }\n",
    "        target_ids = product_ids[self.seq_len: self.seq_len+self.pred_len]\n",
    "        \n",
    "        return input_tokens, ratings[:self.seq_len], categories[:self.seq_len], target_ids\n",
    "\n",
    "train_dataset = UserDataset(train_data, tokenizer, category_encoder, product_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model architecture\n",
    "\n",
    "def my_function(input_ids, attention_mask, token_type_ids):\n",
    "    print(\"input_ids:\", input_ids)\n",
    "    print(\"attention_mask:\", attention_mask)\n",
    "    print(\"token_type_ids\", token_type_ids)\n",
    "    \n",
    "    print(\"shape_input_ids:\", input_ids.shape)\n",
    "    print(\"shape_attention_mask:\", attention_mask.shape)\n",
    "    print(\"shape_token_type_ids\", token_type_ids.shape)\n",
    "\n",
    "# Call function with **tokens\n",
    "# my_function(**tokens)\n",
    "\n",
    "class TransformerRecommendationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_categories=3, num_products=1000, d_model=128, nhead=8, num_decoder_layers=3):\n",
    "        super(TransformerRecommendationModel, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_hidden_size = self.bert.config.hidden_size \n",
    "        \n",
    "        self.fc_features = nn.Linear(bert_hidden_size+1, d_model) # Bert output + rating\n",
    "        self.category_embedding = nn.Embedding(num_categories, d_model)\n",
    "        \n",
    "        self.tgt_embedding = nn.Embedding(num_products, d_model)\n",
    "        \n",
    "        # Transformer Decoder\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=num_decoder_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, num_products)\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "        \n",
    "    \n",
    "    def forward(self, tokens, ratings, categories, tgt):\n",
    "        batch_size, seq_len, max_token_length = tokens[\"input_ids\"].shape\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"].view(-1, max_token_length)  # [batch_size * seq_len, max_token_length]\n",
    "        attention_mask = tokens[\"attention_mask\"].view(-1, max_token_length)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].view(-1, max_token_length)\n",
    "        \n",
    "        pooler_out = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        ).pooler_output\n",
    "        \n",
    "#         print(\"pooler output shape\", pooler_out.shape)\n",
    "#         batch_size, seq_len, _ = ratings.shape\n",
    "        ratings = ratings.view(batch_size * seq_len, -1).float()\n",
    "#         print(\"ratings shape\", ratings.shape)\n",
    "        x = torch.cat([pooler_out, ratings], dim=-1) # add ratings\n",
    "        x = self.fc_features(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "#         print(\"x shape\", x.shape)\n",
    "        \n",
    "        category_embeds = self.category_embedding(categories).float()\n",
    "#         print(\"category embeds shape\",category_embeds.shape)\n",
    "        x = x.view(batch_size,seq_len,-1)\n",
    "        x = x + category_embeds\n",
    "        \n",
    "        x = self.activation(x)\n",
    "        x = self.layer_norm(x)\n",
    "#         print(\"x+category shape\", x.shape)\n",
    "        \n",
    "        \n",
    "#         memory = x.repeat(1, tgt.size(1), 1).reshape(batch_size, tgt.size(1), -1)\n",
    "        memory = x.view(batch_size, seq_len, -1)\n",
    "#         tgt = tgt.float()\n",
    "#         print(\"memory shape\", memory.shape)\n",
    "        \n",
    "        \n",
    "        tgt_embeds = self.tgt_embedding(tgt)\n",
    "#         print(\"tgt_embeds shape:\", tgt_embeds.shape)\n",
    "        \n",
    "#         print(tgt_embeds)\n",
    "        \n",
    "#         print(memory)\n",
    "        decoded = self.decoder(tgt=tgt_embeds, memory=memory)\n",
    "#         print(\"decoded shape\", decoded.shape)\n",
    "        logits = self.fc_out(decoded)\n",
    "#         print(\"logits shape\", logits.shape)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting configuration\n",
    "model = TransformerRecommendationModel(num_categories=len(category_encoder.classes_), num_products=len(product_encoder.classes_)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in model.parameters():\n",
    "#     assert param.device.type == \"cpu\", \"Model parameters must be on CPU\"\n",
    "\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnt=0\n",
    "# for tokens, ratings, categories, target_ids in train_loader:\n",
    "#     cnt+=1\n",
    "#     print(cnt)\n",
    "#     # Check tokens shape consistency\n",
    "#     token_shapes = {key: tensor.shape for key, tensor in tokens.items()}\n",
    "#     assert all(shape == next(iter(token_shapes.values())) for shape in token_shapes.values()), \\\n",
    "#         f\"Inconsistent shapes in tokens: {token_shapes}\"\n",
    "\n",
    "#     # Check ratings shape consistency\n",
    "#     assert all(ratings[0].shape == rating.shape for rating in ratings), \\\n",
    "#         f\"Inconsistent shapes in ratings: {[rating.shape for rating in ratings]}\"\n",
    "\n",
    "#     # Check categories shape consistency\n",
    "#     category_shape = categories.shape\n",
    "#     assert all(categories[0].shape == cat.shape for cat in categories), \\\n",
    "#         f\"Inconsistent shapes in categories: {[cat.shape for cat in categories]}\"\n",
    "\n",
    "#     # Check target_ids shape consistency\n",
    "# #     target_id_shape = target_ids.shape\n",
    "#     assert all(target_ids[0].shape == target.shape for target in target_ids), \\\n",
    "#         f\"Inconsistent shapes in target_ids: {[target.shape for target in target_ids]}\"\n",
    "\n",
    "#     print(\"Batch shapes are consistent for tokens, ratings, categories, and target_ids.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Writing Train loop\n",
    "\n",
    "# for epoch in range(5):\n",
    "#     model.train()\n",
    "#     cnt=0\n",
    "#     for tokens, ratings, categories, target_ids in train_loader:\n",
    "#         cnt+=1\n",
    "#         print(cnt)\n",
    "#         optimizer.zero_grad()\n",
    "#         tokens = {\n",
    "#             \"input_ids\": tokens[\"input_ids\"].to(device),\n",
    "#             \"attention_mask\": tokens[\"attention_mask\"].to(device),\n",
    "#             \"token_type_ids\": tokens[\"token_type_ids\"].to(device),\n",
    "#         }\n",
    "#         ratings = ratings.to(device)\n",
    "#         categories = categories.to(device)\n",
    "#         target_ids = target_ids.to(device)\n",
    "        \n",
    "#         print(\"target ids shape\", target_ids.shape)\n",
    "        \n",
    "        \n",
    "#         logits = model(tokens, ratings, categories, target_ids)\n",
    "# #         loss = criterion(logits.view(-1, logits.size(-1)), target_ids.view(-1))\n",
    "\n",
    "#         logits = logits.view(-1, logits.size(-1))  # [batch_size * tgt_seq_len, num_products]\n",
    "#         targets = target_ids.view(-1)\n",
    "#         print(targets)\n",
    "#         assert targets.dtype == torch.long\n",
    "        \n",
    "# #         print(\"Target range:\", target.min().item(), target.max().item())\n",
    "# #         print(\"Logits shape:\", logits.shape)\n",
    "# #         assert target.max() < logits.size(-1), \"Target index out of range\"\n",
    "# #         assert target.min() >= 0, \"Target index must be non-negative\"\n",
    "\n",
    "#         loss = criterion(logits, targets)\n",
    "        \n",
    "#         loss.backward()\n",
    "#         print(loss.item())\n",
    "# #         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "#         optimizer.step()\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 365/365 [20:19<00:00,  3.34s/it, loss=10.2]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'baseline_model.pth'\n",
      "Epoch 1, Average Loss: 10.2518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Writing Train loop\n",
    "\n",
    "for epoch in range(1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", leave=True)\n",
    "    \n",
    "    for tokens, ratings, categories, target_ids in progress_bar:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        tokens = {\n",
    "            \"input_ids\": tokens[\"input_ids\"].to(device),\n",
    "            \"attention_mask\": tokens[\"attention_mask\"].to(device),\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"].to(device),\n",
    "        }\n",
    "        ratings = ratings.to(device)\n",
    "        categories = categories.to(device)\n",
    "        target_ids = target_ids.to(device)\n",
    "        \n",
    "#         print(\"target ids shape\", target_ids.shape)\n",
    "        \n",
    "        \n",
    "        logits = model(tokens, ratings, categories, target_ids)\n",
    "#         loss = criterion(logits.view(-1, logits.size(-1)), target_ids.view(-1))\n",
    "        \n",
    "        predicted_indices = torch.argmax(logits, dim=-1)\n",
    "#         print(\"Predicted items\",predicted_indices.shape, predicted_indices)\n",
    "        \n",
    "        logits = logits.view(-1, logits.size(-1))  # [batch_size * tgt_seq_len, num_products]\n",
    "        targets = target_ids.view(-1)\n",
    "        \n",
    "        \n",
    "#         print(targets)\n",
    "#         assert targets.dtype == torch.long\n",
    "        \n",
    "#         print(\"Target range:\", target.min().item(), target.max().item())\n",
    "#         print(\"Logits shape:\", logits.shape)\n",
    "#         assert target.max() < logits.size(-1), \"Target index out of range\"\n",
    "#         assert target.min() >= 0, \"Target index must be non-negative\"\n",
    "\n",
    "        loss = criterion(logits, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "#         print(loss.item())\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "#         print(loss.item())\n",
    "    \n",
    "#     torch.save(model.state_dict(), \"baseline_model.pth\")\n",
    "    print(\"Model's state dictionary saved to 'baseline_model.pth'\")\n",
    "    print(f\"Epoch {epoch + 1}, Average Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "#     print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'baseline_model.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"baseline_model.pth\")\n",
    "print(\"Model's state dictionary saved to 'baseline_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_201306/1315652952.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"baseline_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"baseline_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(logits, target_ids, k=5):\n",
    "    print(\"***********\")\n",
    "    preds = torch.topk(logits, k=k, dim=-1).indices\n",
    "    \n",
    "    correct = (preds == target_ids.unsqueeze(-1)).any(dim=-1)\n",
    "    \n",
    "    print(preds, target_ids.unsqueeze(-1))\n",
    "    \n",
    "    recall = correct.float().mean().item()\n",
    "    return recall\n",
    "\n",
    "def mean_reciprocal_rank(logits, target_ids):\n",
    "    rankings = torch.argsort(logits, dim=-1, descending=True)\n",
    "    target_ranks = (rankings==target_ids.unsqueeze(-1)).nonzero(as_tuple=True)[-1]+1\n",
    "    \n",
    "    reciprocal_ranks = 1.0/target_ranks.float()\n",
    "    mrr = reciprocal_ranks.mean().item()\n",
    "    return mrr\n",
    "\n",
    "def precision_at_k(logits, target_ids, k=5):\n",
    "    top_k_preds = torch.topk(logits, k=k, dim=-1).indices\n",
    "    \n",
    "    correct = (top_k_preds == target_ids.unsqueeze(-1)).float()\n",
    "    \n",
    "    precision = correct.sum(dim=-1)/k\n",
    "    precision = precision.mean().item()\n",
    "    return precision\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, product_encoder, k=5, output_file=\"predictions.txt\"):\n",
    "    model.eval()\n",
    "    recall = 0\n",
    "    mrr = 0\n",
    "    precision_k = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with open(output_file, \"w\") as f:\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=\"Evaluating\", leave=True):\n",
    "                \n",
    "                tokens, ratings, categories, target_ids = batch\n",
    "#                 print(target_ids)\n",
    "                ratings = ratings.to(device)\n",
    "                categories = categories.to(device)\n",
    "                target_ids = target_ids.to(device)\n",
    "\n",
    "                tokens = {\n",
    "                    \"input_ids\": tokens[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": tokens[\"attention_mask\"].to(device),\n",
    "                    \"token_type_ids\": tokens[\"token_type_ids\"].to(device),\n",
    "                }\n",
    "\n",
    "                logits = model(tokens, ratings, categories, target_ids)\n",
    "                \n",
    "                \n",
    "                predicted_indices = torch.argmax(logits, dim=-1)\n",
    "#                 print(\"Predicted items\",predicted_indices)\n",
    "                \n",
    "                for i in range(target_ids.size(0)):\n",
    "                        print(target_ids[i])\n",
    "                        actual = [product_encoder.inverse_transform([target_ids[i,j].item()])[0] for j in range(target_ids.size(1))]\n",
    "                        print(actual)\n",
    "                        predicted = [product_encoder.inverse_transform([predicted_indices[i,j].item()])[0] for j in range(target_ids.size(1))]\n",
    "                        f.write(f\"{predicted} ---- {actual}\\n\")\n",
    "\n",
    "                batch_size = target_ids.size(0)\n",
    "                recall+= compute_recall(logits, target_ids, k=k)*batch_size\n",
    "                mrr+= mean_reciprocal_rank(logits, target_ids)*batch_size\n",
    "                precision_k+=precision_at_k(logits, target_ids, k=k)*batch_size\n",
    "                total_samples+=batch_size\n",
    "                break\n",
    "\n",
    "            metrics = {\n",
    "                \"Recall\": recall/total_samples,\n",
    "                \"MRR\": mrr/total_samples,\n",
    "                \"Precision@{}\".format(k): precision_k/total_samples,\n",
    "            }\n",
    "            return metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/365 [00:02<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28771, 38818,  8920,  9639,  3799], device='cuda:0')\n",
      "['B0948G4LMS', 'B0C144331J', 'B00L9DSWGQ', 'B00O6UCXUK', 'B005C07F6K']\n",
      "tensor([ 3407, 19918, 10536, 38791, 31042], device='cuda:0')\n",
      "['B004T8NOR0', 'B07FK63PSH', 'B00TX1KILI', 'B0BZXB1CK6', 'B09NT5ZK6T']\n",
      "tensor([ 6025, 12609, 38354,  3141,  8102], device='cuda:0')\n",
      "['B00B1M2N88', 'B01AANNCP6', 'B0BXW17H4C', 'B004JU0H7I', 'B00HZFJQ12']\n",
      "tensor([13234, 22257, 21550, 10111, 27026], device='cuda:0')\n",
      "['B01DNYOKHS', 'B07QGVYYYX', 'B07MX3QGR1', 'B00Q4X2FSM', 'B08M1DGKK4']\n",
      "tensor([27049,  2127, 14827, 36900, 13288], device='cuda:0')\n",
      "['B08M6ZCRRT', 'B0034GGCY0', 'B01MD05Q8F', 'B0BQ7F2RW9', 'B01DY8MMQY']\n",
      "tensor([36723, 32400, 22456, 20831, 25123], device='cuda:0')\n",
      "['B0BPB8Z23R', 'B09Y7L9KBW', 'B07R7WLHXS', 'B07JVQ28QR', 'B085ZB581W']\n",
      "tensor([22823,  2153,  6469, 21077, 16337], device='cuda:0')\n",
      "['B07SSCCTCG', 'B0035ER4WU', 'B00C6CS8PE', 'B07KVVXLMY', 'B0728F31F6']\n",
      "tensor([19792, 39702, 32026, 19259, 16719], device='cuda:0')\n",
      "['B07F3Q518C', 'B0C66LKVB9', 'B09W7KBM2H', 'B07CV6ZY4K', 'B0741BMLP9']\n",
      "tensor([31120, 34745,  4421,   282,  9776], device='cuda:0')\n",
      "['B09P5SNK1Q', 'B0BD887ZH1', 'B006VB29D8', 'B000BNCA4K', 'B00OQCZAVW']\n",
      "tensor([14532, 39133, 30450, 21950, 25981], device='cuda:0')\n",
      "['B01LZ2ZVCY', 'B0C36YXDG4', 'B09KC7BDWM', 'B07PDJBXBB', 'B08C4XK8RF']\n",
      "tensor([12767, 34442,   164,  3299,   824], device='cuda:0')\n",
      "['B01B7IZTGI', 'B0BB84JXS9', 'B0006BAJN6', 'B004PX5KBC', 'B0012E4FV8']\n",
      "tensor([26323, 14196, 29525, 34942, 33688], device='cuda:0')\n",
      "['B08FD9VQSG', 'B01K3SOW98', 'B099XCVRJZ', 'B0BFHP8JPG', 'B0B63QBWFQ']\n",
      "tensor([ 2753, 34184,  7561, 23517,  8623], device='cuda:0')\n",
      "['B0045I6IAO', 'B0B9278KY1', 'B00FXOYGCQ', 'B07WJ6H5NV', 'B00JS7XYWW']\n",
      "tensor([ 2098, 33560, 37096,  7787, 30712], device='cuda:0')\n",
      "['B0032LY2GM', 'B0B5JP4MGX', 'B0BR7X2DHT', 'B00GULB16U', 'B09M84SLW2']\n",
      "tensor([ 1011,  2405,    49, 40123,  4404], device='cuda:0')\n",
      "['B001CAZGMY', 'B003HKQ8GK', 'B000056W6H', 'B0C9P3LBJ7', 'B006TWH4R0']\n",
      "tensor([38474,  4145,  2248,  4631, 37661], device='cuda:0')\n",
      "['B0BYJM3F1V', 'B005Z9HO1O', 'B0038JE5Y2', 'B007A2ZOP2', 'B0BTV3G59T']\n",
      "***********\n",
      "tensor([[[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306,  7789],\n",
      "         [  282,  9776, 11281, 40306,  7789],\n",
      "         [  282,  9776, 11281, 40306,  7789],\n",
      "         [  282,  9776, 11281, 40306,  7789],\n",
      "         [  282,  9776, 11281, 40306,  7789]],\n",
      "\n",
      "        [[  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789],\n",
      "         [  282, 11281,  9776, 40306,  7789]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]],\n",
      "\n",
      "        [[  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298],\n",
      "         [  282,  9776, 11281, 40306, 30298]]], device='cuda:0') tensor([[[28771],\n",
      "         [38818],\n",
      "         [ 8920],\n",
      "         [ 9639],\n",
      "         [ 3799]],\n",
      "\n",
      "        [[ 3407],\n",
      "         [19918],\n",
      "         [10536],\n",
      "         [38791],\n",
      "         [31042]],\n",
      "\n",
      "        [[ 6025],\n",
      "         [12609],\n",
      "         [38354],\n",
      "         [ 3141],\n",
      "         [ 8102]],\n",
      "\n",
      "        [[13234],\n",
      "         [22257],\n",
      "         [21550],\n",
      "         [10111],\n",
      "         [27026]],\n",
      "\n",
      "        [[27049],\n",
      "         [ 2127],\n",
      "         [14827],\n",
      "         [36900],\n",
      "         [13288]],\n",
      "\n",
      "        [[36723],\n",
      "         [32400],\n",
      "         [22456],\n",
      "         [20831],\n",
      "         [25123]],\n",
      "\n",
      "        [[22823],\n",
      "         [ 2153],\n",
      "         [ 6469],\n",
      "         [21077],\n",
      "         [16337]],\n",
      "\n",
      "        [[19792],\n",
      "         [39702],\n",
      "         [32026],\n",
      "         [19259],\n",
      "         [16719]],\n",
      "\n",
      "        [[31120],\n",
      "         [34745],\n",
      "         [ 4421],\n",
      "         [  282],\n",
      "         [ 9776]],\n",
      "\n",
      "        [[14532],\n",
      "         [39133],\n",
      "         [30450],\n",
      "         [21950],\n",
      "         [25981]],\n",
      "\n",
      "        [[12767],\n",
      "         [34442],\n",
      "         [  164],\n",
      "         [ 3299],\n",
      "         [  824]],\n",
      "\n",
      "        [[26323],\n",
      "         [14196],\n",
      "         [29525],\n",
      "         [34942],\n",
      "         [33688]],\n",
      "\n",
      "        [[ 2753],\n",
      "         [34184],\n",
      "         [ 7561],\n",
      "         [23517],\n",
      "         [ 8623]],\n",
      "\n",
      "        [[ 2098],\n",
      "         [33560],\n",
      "         [37096],\n",
      "         [ 7787],\n",
      "         [30712]],\n",
      "\n",
      "        [[ 1011],\n",
      "         [ 2405],\n",
      "         [   49],\n",
      "         [40123],\n",
      "         [ 4404]],\n",
      "\n",
      "        [[38474],\n",
      "         [ 4145],\n",
      "         [ 2248],\n",
      "         [ 4631],\n",
      "         [37661]]], device='cuda:0')\n",
      "Test Metrics:\n",
      "Recall:  0.0250\n",
      "MRR:  0.0217\n",
      "Precision@5:  0.0050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_metrics = evaluate_model(model, train_loader,product_encoder, k=5, output_file=\"baseline_predictions_comparision.txt\")\n",
    "print(\"Test Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: {'input_ids': tensor([[[  101, 29324,  2130,  ...,  2489,  1997,   102],\n",
      "         [  101,  3008,  2022,  ...,  1010, 12109,   102],\n",
      "         [  101,  2061, 14057,  ...,  2043,  2026,   102],\n",
      "         ...,\n",
      "         [  101,  3819,  3336,  ...,  8744,  3111,   102],\n",
      "         [  101,  1996,  2069,  ...,  4906,  1025,   102],\n",
      "         [  101,  1037,  2210,  ...,  2053, 11669,   102]],\n",
      "\n",
      "        [[  101, 11937, 21756,  ...,  1012,  2061,   102],\n",
      "         [  101,  2200,  3733,  ...,  7554, 20631,   102],\n",
      "         [  101,  2053, 10514,  ...,  5127,  2838,   102],\n",
      "         ...,\n",
      "         [  101,  2204,  8962,  ...,  2675,  1007,   102],\n",
      "         [  101,  2844,  5437,  ...,     0,     0,     0],\n",
      "         [  101, 24325,  2023,  ...,  1006,  8698,   102]],\n",
      "\n",
      "        [[  101,  2305,  7138,  ...,  1012,  2023,   102],\n",
      "         [  101,  4268,  5527,  ...,  8026,  5761,   102],\n",
      "         [  101,  4845,  1005,  ...,  2028,  3538,   102],\n",
      "         ...,\n",
      "         [  101,  6927,  3917,  ...,  2053,  9781,   102],\n",
      "         [  101, 26352,  8248,  ...,  5744,  2121,   102],\n",
      "         [  101, 10007, 19351,  ...,  2005,  3679,   102]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[  101,  2307,  2005,  ...,     0,     0,     0],\n",
      "         [  101,  2023,  2003,  ...,  2190,  2112,   102],\n",
      "         [  101,  1045,  2066,  ..., 14397, 18095,   102],\n",
      "         ...,\n",
      "         [  101,  2027,  2024,  ...,  2403,  2378,   102],\n",
      "         [  101,  2174,  1996,  ...,  1996,  2087,   102],\n",
      "         [  101,  2307, 23766,  ...,  3436,  1999,   102]],\n",
      "\n",
      "        [[  101,  2307,  5510,  ...,  8261, 14894,   102],\n",
      "         [  101,  2074,  3100,  ...,     0,     0,     0],\n",
      "         [  101,  7619,  2442,  ...,  7619,  2442,   102],\n",
      "         ...,\n",
      "         [  101,  3733,  2000,  ...,  4317,  1998,   102],\n",
      "         [  101,  2028,  2732,  ...,  6081,  1010,   102],\n",
      "         [  101,  6211,  2000,  ...,  2151,  5909,   102]],\n",
      "\n",
      "        [[  101,  2573,  2005,  ...,  2007,  2115,   102],\n",
      "         [  101,  3849,  2000,  ...,  2034,  1012,   102],\n",
      "         [  101,  3492,  2779,  ...,  2036,  2134,   102],\n",
      "         ...,\n",
      "         [  101,  2204,  4906,  ...,  2098,  2503,   102],\n",
      "         [  101,  2066, 17492,  ...,  1012,  1996,   102],\n",
      "         [  101, 19638,  2084,  ...,  1037,  2843,   102]]]), 'attention_mask': tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 0, 0, 0],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]],\n",
      "\n",
      "        [[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]]), 'token_type_ids': tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]])}\n",
      "Ratings: tensor([[0.2500, 0.0000, 1.0000, 1.0000, 0.7500, 1.0000, 0.7500, 0.7500, 1.0000,\n",
      "         0.7500, 0.7500, 0.5000, 1.0000, 1.0000, 0.7500],\n",
      "        [1.0000, 0.7500, 0.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 0.0000,\n",
      "         1.0000, 1.0000, 0.5000, 1.0000, 0.5000, 0.2500],\n",
      "        [0.2500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.7500, 1.0000, 1.0000, 0.5000, 1.0000, 0.7500],\n",
      "        [0.5000, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500, 0.7500,\n",
      "         1.0000, 0.7500, 0.7500, 1.0000, 0.2500, 0.7500],\n",
      "        [0.5000, 0.2500, 0.0000, 0.2500, 1.0000, 0.7500, 0.7500, 0.5000, 1.0000,\n",
      "         0.5000, 1.0000, 0.7500, 0.7500, 0.5000, 1.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 0.7500, 0.7500, 1.0000, 1.0000],\n",
      "        [0.5000, 0.7500, 1.0000, 0.5000, 0.7500, 0.7500, 0.7500, 1.0000, 0.5000,\n",
      "         1.0000, 1.0000, 0.7500, 1.0000, 1.0000, 0.5000],\n",
      "        [0.5000, 0.0000, 0.7500, 1.0000, 1.0000, 0.5000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 1.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "        [0.5000, 0.2500, 0.0000, 0.7500, 0.7500, 0.7500, 0.2500, 0.0000, 0.2500,\n",
      "         0.5000, 0.5000, 1.0000, 1.0000, 0.7500, 0.5000],\n",
      "        [0.5000, 1.0000, 0.5000, 1.0000, 0.5000, 1.0000, 1.0000, 0.5000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 0.5000, 0.7500, 1.0000],\n",
      "        [0.7500, 1.0000, 0.7500, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         1.0000, 1.0000, 1.0000, 1.0000, 0.7500, 1.0000],\n",
      "        [0.7500, 0.5000, 1.0000, 1.0000, 0.7500, 0.7500, 0.2500, 0.7500, 0.5000,\n",
      "         1.0000, 0.7500, 0.7500, 0.7500, 0.7500, 0.0000],\n",
      "        [0.7500, 0.7500, 0.5000, 0.7500, 1.0000, 0.5000, 1.0000, 0.7500, 0.7500,\n",
      "         1.0000, 0.7500, 0.7500, 0.7500, 0.5000, 0.7500]])\n",
      "Categories: tensor([[ 7,  7,  7,  7,  7,  3,  7,  7,  7,  7,  7,  7, 18,  7,  7],\n",
      "        [14, 16,  7,  3,  3,  3,  7,  3,  7,  7,  7, 14,  7,  7,  7],\n",
      "        [ 7, 18,  0, 14, 14, 14, 14, 14,  7,  7, 25,  7, 16,  1, 16],\n",
      "        [ 7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7, 16,  7,  7,  7],\n",
      "        [16,  6,  1,  7,  7, 24, 14,  7,  7,  7,  3,  7,  7,  7,  7],\n",
      "        [ 1, 14,  7, 14,  7,  3, 14,  7, 14, 14,  7,  7,  1, 16, 14],\n",
      "        [23, 16,  7, 16, 24,  7, 23,  0,  7,  7, 16,  7,  7,  7,  7],\n",
      "        [ 7,  7,  7,  7,  7,  7,  7,  3,  7,  7,  7,  7,  7,  1,  7],\n",
      "        [ 1, 16,  7,  7,  3,  7,  7,  7,  7,  3, 26,  7,  7,  7,  7],\n",
      "        [ 3, 16,  7,  7,  3, 16,  7,  7,  7, 16,  7, 20,  3, 16,  7],\n",
      "        [26, 26,  3,  7,  7,  7,  7, 26, 26,  7,  7,  7,  7,  6,  7],\n",
      "        [16, 16, 16, 16, 16, 16, 16, 16,  3, 16, 16, 16, 16,  7, 14],\n",
      "        [ 1,  1,  1,  1, 16, 16, 16, 16, 16, 16,  7,  7, 24,  7,  3],\n",
      "        [ 1,  7,  7,  7, 16,  7, 16, 16, 18,  7,  7,  0,  0,  7,  7],\n",
      "        [16, 16,  7,  7,  3,  7,  7,  7,  7,  3,  1,  7,  7,  7,  7],\n",
      "        [ 1,  1,  1,  1,  1,  1, 16, 16, 16, 16, 16, 16, 16, 16, 16]])\n",
      "Target IDs: tensor([[42502,  2443,  9692, 24639,  7960],\n",
      "        [27193, 42914, 33939, 24167, 33939],\n",
      "        [21942, 14839, 31586, 27126, 22729],\n",
      "        [ 6843, 25526, 15125,  9768, 37714],\n",
      "        [ 6105, 18745, 12016,  7868,  8951],\n",
      "        [12007, 30585, 42635, 19567, 22053],\n",
      "        [19665, 35690, 34707, 17522,  9964],\n",
      "        [ 4040,  5297,   718, 19866,  1254],\n",
      "        [38740, 24655, 34149, 42862, 21330],\n",
      "        [ 5350, 22872, 13731, 38543,  8286],\n",
      "        [39096, 39373, 41507, 42361, 39627],\n",
      "        [15461, 12237, 42289, 11769, 12206],\n",
      "        [ 4214, 22192, 42381,  8845, 14764],\n",
      "        [ 4986, 23909,   757, 36310, 40151],\n",
      "        [42617, 14331, 15104,  1039,  7562],\n",
      "        [25279, 20135, 17141, 42766, 41467]])\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "for tokens, ratings, categories, target_ids in train_loader:\n",
    "    print(\"Tokens:\", tokens)\n",
    "    print(\"Ratings:\", ratings)\n",
    "    print(\"Categories:\", categories)\n",
    "    print(\"Target IDs:\", target_ids)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
