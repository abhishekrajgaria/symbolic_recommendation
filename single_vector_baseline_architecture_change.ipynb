{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e380ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/numpy-1.22.3-py3.10-linux-x86_64.egg (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/networkx-2.8.6-py3.10.egg (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/Jinja2-3.0.3-py3.10.egg (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/MarkupSafe-2.1.1-py3.10-linux-x86_64.egg (from jinja2->torch) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4412b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d996ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b9f5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/user_history_full_data.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(user_history_filepath, 'r')\n",
    "user_history = json.load(json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45f6be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_with_history_sizes(user_h):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for user_id in user_history.keys():\n",
    "        cnt_dict[len(user_history[user_id])]+=1\n",
    "    print(cnt_dict)\n",
    "    \n",
    "def count_user_with_history_size_above(user_h, above):\n",
    "    cnt = 0\n",
    "    for user_id in user_history.keys():\n",
    "        if len(user_history[user_id]) >= above:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\n",
    "def filter_users(user_h, min_history_length, max_history_length=-1)->dict:\n",
    "    filtered_users = {}\n",
    "    count=0\n",
    "    for user, history in user_h.items():\n",
    "        if len(history) >= min_history_length:\n",
    "            filtered_users[user] = history[:max_history_length]\n",
    "            count+=1\n",
    "        \n",
    "        if count==-1:\n",
    "            break\n",
    "    return filtered_users\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b5f7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297\n"
     ]
    }
   ],
   "source": [
    "filtered_users = filter_users(user_history, 20, 50)\n",
    "print(len(filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9263e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177b8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d33587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 4669, Validation users: 1168, Test users: 1460\n"
     ]
    }
   ],
   "source": [
    "users = list(filtered_users.keys())\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train users into train (80%) and validation (20%) within the training set\n",
    "train_users, val_users = train_test_split(train_users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train, validation, and test data dictionaries\n",
    "train_data = {user: filtered_users[user] for user in train_users}\n",
    "val_data = {user: filtered_users[user] for user in val_users}\n",
    "test_data = {user: filtered_users[user] for user in test_users}\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train users: {len(train_users)}, Validation users: {len(val_users)}, Test users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e3ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "main_category_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2939bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_categories = [entry[\"main_category\"] for user in users for entry in filtered_users[user]]\n",
    "main_category_encoder.fit(main_categories)\n",
    "categories = [entry[\"categories\"] for user in users for entry in filtered_users[user]]\n",
    "category_encoder.fit(categories)\n",
    "product_ids = [entry[\"product_id\"] for user in users for entry in filtered_users[user]]\n",
    "product_encoder.fit(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a786003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_category_product_mappings(data, category_encoder, product_encoder):\n",
    "    category_index_to_products = defaultdict(list)\n",
    "    for user, histories in data.items():\n",
    "        for history in histories:\n",
    "            #print([history['categories'][-1]])\n",
    "            category_idx = category_encoder.transform([history['categories'][-1]])[0]\n",
    "            product_idx = product_encoder.transform([history['product_id']])[0]\n",
    "            category_index_to_products[category_idx].append(product_idx)\n",
    "        \n",
    "        category_index_to_products = {k: list(set(v)) for k, v in category_index_to_products.items()}\n",
    "        return category_index_to_products\n",
    "\n",
    "category_index_to_products = generate_category_product_mappings(filtered_users, category_encoder, product_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ad48488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(histories):\n",
    "    all_ratings = [h[\"rating\"] for user in histories for h in histories[user]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit([[r] for r in all_ratings])\n",
    "    return scaler\n",
    "\n",
    "rating_scaler = normalize_ratings(filtered_users)\n",
    "\n",
    "def preprocess_history(history):\n",
    "    texts = [\n",
    "        f\"{h.get('review_title','')} {h.get('features','')} {h.get('main_category')}\" for h in history\n",
    "    ]\n",
    "    \n",
    "    texts = [text for text in texts if text.strip()]\n",
    "    \n",
    "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    ratings = torch.tensor([rating_scaler.transform([[h[\"rating\"]]])[0][0] for h in history], dtype=torch.float32)\n",
    "    \n",
    "    #categories = torch.tensor(category_encoder.transform([h[\"main_category\"] for h in history]))\n",
    "    \n",
    "    categories = torch.tensor(category_encoder.transform([h[\"categories\"] for h in history]))\n",
    "    \n",
    "    product_ids = torch.tensor(product_encoder.transform([h[\"product_id\"] for h in history]))\n",
    "    \n",
    "    return tokens, ratings, categories, product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5c45703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, category_encoder, product_encoder, seq_len=15, pred_len=5):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.category_encoder = category_encoder # Is it required?\n",
    "        self.product_encoder = product_encoder # Is it required?\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, history = list(self.data.items())[idx]\n",
    "        tokens, ratings, categories, product_ids = preprocess_history(history)\n",
    "        input_tokens = {\n",
    "            \"input_ids\":tokens[\"input_ids\"][:self.seq_len],\n",
    "            \"attention_mask\": tokens[\"attention_mask\"][:self.seq_len],\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"][:self.seq_len],\n",
    "        }\n",
    "        input_ratings = ratings[:self.seq_len]\n",
    "        input_categories = categories[:self.seq_len]\n",
    "        \n",
    "        future_categories = categories[self.seq_len:]\n",
    "        \n",
    "        future_products = product_ids[self.seq_len:]\n",
    "        \n",
    "        target_category_vector = torch.zeros(len(self.category_encoder.classes_))\n",
    "        target_category_vector[future_categories] = 1\n",
    "        \n",
    "        target_vector = torch.zeros(len(self.product_encoder.classes_))\n",
    "        target_vector[future_products] = 1\n",
    "        \n",
    "        return input_tokens, input_ratings, input_categories, target_category_vector, target_vector\n",
    "\n",
    "train_dataset = UserDataset(train_data, tokenizer, category_encoder, product_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84c5d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleVectorTransformerRecommendationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_categories=900, num_products=1000, d_model=128, nhead=8, num_encoder_layers=3):\n",
    "        super(SingleVectorTransformerRecommendationModel, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        self.category_embedding = nn.Embedding(num_categories, d_model)\n",
    "        \n",
    "        self.history_encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.history_encoder = nn.TransformerEncoder(self.history_encoder_layer, num_layers = num_encoder_layers)\n",
    "         \n",
    "        self.input_projection = nn.Linear(bert_hidden_size + d_model, d_model)\n",
    "            \n",
    "        self.product_category_fc = nn.Linear(d_model, num_categories)\n",
    "        self.product_fc = nn.Linear(d_model, num_products)\n",
    "        \n",
    "        self.activation = nn.ReLU()\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, tokens, ratings, categories, category_to_product_map=None):\n",
    "        batch_size, seq_len, max_token_length = tokens[\"input_ids\"].shape\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"].view(-1, max_token_length)\n",
    "        attention_mask = tokens[\"attention_mask\"].view(-1, max_token_length)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].view(-1, max_token_length)\n",
    "        \n",
    "        bert_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "        sequence_output = sequence_output[:,0,:].view(batch_size, seq_len, -1)\n",
    "\n",
    "        \n",
    "        category_embeds = self.category_embedding(categories)\n",
    "        combined_features = torch.cat([sequence_output, category_embeds], dim=-1)\n",
    "        projected_features = self.input_projection(combined_features)\n",
    "        normalized_features = self.layer_norm(projected_features)  # Apply LayerNorm\n",
    "        activated_features = self.activation(normalized_features) \n",
    "        \n",
    "        history_output = self.history_encoder(activated_features)\n",
    "        user_representation = history_output.mean(dim=1)\n",
    "        \n",
    "        normalized_output = self.layer_norm(user_representation)  # Apply LayerNorm\n",
    "        activated_output = self.activation(normalized_output)  # Apply activation\n",
    "        \n",
    "        product_category_logits = self.product_category_fc(activated_output)\n",
    "        product_logits = self.product_fc(activated_output)\n",
    "        \n",
    "        if category_to_product_map is not None:\n",
    "            for i in range(batch_size):\n",
    "                product_mask = torch.zeros_like(product_logits[i])  # [num_products]\n",
    "                for category_idx, category_logit in enumerate(product_category_logits[i]):\n",
    "                    if category_idx in category_to_product_map:\n",
    "                        valid_product_indices = category_to_product_map[category_idx]\n",
    "                        product_mask[valid_product_indices] += category_logit\n",
    "                product_logits[i] *= product_mask\n",
    "        \n",
    "        \n",
    "        \n",
    "        product_probabilities = self.sigmoid(product_logits)  # [batch_size, num_products]\n",
    "        product_category_probabilities = self.sigmoid(product_category_logits) \n",
    "        \n",
    "        return product_probabilities, product_category_probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5af27b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute Top-K accuracy for multi-label classification.\n",
    "    Args:\n",
    "        predicted_vector (Tensor): Predicted probabilities for products [batch_size, num_products].\n",
    "        target_vector (Tensor): Binary target vector [batch_size, num_products].\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        top_k_accuracy (float): Top-K accuracy for the batch.\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch\n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "    # Gather the target values corresponding to the top-k predictions\n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "    # Count how many of the top-k predictions are correct\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Compute the accuracy as the mean of correct predictions\n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "\n",
    "    return top_k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b895438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_metrics(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute top-k accuracy and precision for classification tasks.\n",
    "    \n",
    "    Args:\n",
    "        predicted_vector (torch.Tensor): Predicted probabilities or logits\n",
    "        target_vector (torch.Tensor): Ground truth labels\n",
    "        k (int, optional): Number of top predictions to consider. Defaults to 5.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing top-k accuracy and precision\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch \n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k] \n",
    " \n",
    "    # Gather the target values corresponding to the top-k predictions \n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k] \n",
    " \n",
    "    # Compute top-k accuracy\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size] \n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "    \n",
    "    # Compute top-k precision\n",
    "    # Precision = (number of correct predictions in top-k) / (total number of top-k predictions)\n",
    "    correct_predictions_count = true_positives.sum()\n",
    "    top_k_precision = correct_predictions_count / (top_k_preds.shape[0] * k)\n",
    "    \n",
    "    return top_k_accuracy,top_k_precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f268a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_top_k_precision = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, _, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            target_vector = target_vector.to(device)\n",
    "            categories = categories.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector,_ = model(tokens, ratings, categories, category_to_product_map = category_index_to_products)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc, top_k_prec = compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "\n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_top_k_precision += top_k_prec\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc,\n",
    "                                     \"Batch Top-K prec\": top_k_prec})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "    average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "    average_top_k_precision = total_top_k_precision / total_batches\n",
    "    print(f\"Average Top-{k} Precision: {average_top_k_precision:.4f}\")\n",
    "    return average_top_k_accuracy\n",
    "\n",
    "# Example usage:\n",
    "# average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "val_dataset = UserDataset(val_data, tokenizer, category_encoder, product_encoder)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d59fa52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleVectorTransformerRecommendationModel(num_categories=len(category_encoder.classes_), num_products=len(product_encoder.classes_)).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "# category_loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.bert.parameters(), \"lr\": 1e-5, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.category_embedding.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.input_projection.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.product_category_fc.parameters(), \"lr\": 1e-2, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.history_encoder.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.product_fc.parameters(), \"lr\": 1e-3, \"weight_decay\": 1e-5},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e52db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 292/292 [14:26<00:00,  2.97s/it, Prod Cat Loss=0.693, Prod ID Loss=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Category Loss: 0.6959\n",
      "  Product Loss: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 292/292 [14:28<00:00,  2.98s/it, Prod Cat Loss=0.693, Prod ID Loss=0.974]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "  Category Loss: 0.6931\n",
      "  Product Loss: 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_category_loss = 0.0\n",
    "    total_product_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
    "\n",
    "    for tokens, ratings, categories, target_category_vector, target_vector in progress_bar:\n",
    "        tokens = {key: val.to(device) for key, val in tokens.items()}\n",
    "        ratings = ratings.to(device)\n",
    "        categories = categories.to(device)\n",
    "        target_vector = target_vector.to(device)\n",
    "        target_category_vector = target_category_vector.to(device)\n",
    "        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_product_logits, predicted_category_logits = model(tokens, ratings, categories, category_to_product_map = category_index_to_products)\n",
    "\n",
    "        # Compute loss\n",
    "        product_loss = loss_fn(predicted_product_logits, target_vector.float())\n",
    "        category_loss = loss_fn(predicted_category_logits, target_category_vector.float())\n",
    "        \n",
    "        loss = product_loss + category_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_product_loss += product_loss.item()\n",
    "        total_category_loss += category_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            \"Prod Cat Loss\": category_loss.item(),\n",
    "            \"Prod ID Loss\": product_loss.item(),\n",
    "        })\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    print(f\"  Category Loss: {total_category_loss / len(train_loader):.4f}\")\n",
    "    print(f\"  Product Loss: {total_product_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1332cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'single_vector_arch_change.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"single_vector_arch_change.pth\")\n",
    "print(\"Model's state dictionary saved to 'single_vector_arch_change.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7eb00c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_203114/1714548901.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"single_vector_arch_change.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"single_vector_arch_change.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c0b5682",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68c597a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:19<00:00,  1.83it/s, Batch Top-K Acc=0, Batch Top-K prec=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.0007\n",
      "Average Top-5 Precision: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:18<00:00,  1.84it/s, Batch Top-K Acc=0, Batch Top-K prec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-3 Accuracy: 0.0000\n",
      "Average Top-3 Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:18<00:00,  1.84it/s, Batch Top-K Acc=0, Batch Top-K prec=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.0000\n",
      "Average Top-1 Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=3)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=1)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07c741",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
