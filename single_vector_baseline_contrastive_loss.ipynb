{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e380ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/numpy-1.22.3-py3.10-linux-x86_64.egg (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/networkx-2.8.6-py3.10.egg (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/Jinja2-3.0.3-py3.10.egg (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/MarkupSafe-2.1.1-py3.10-linux-x86_64.egg (from jinja2->torch) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4412b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d996ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b9f5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/user_history_full_data.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f2715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(user_history_filepath, 'r')\n",
    "user_history = json.load(json_file)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45f6be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_with_history_sizes(user_h):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for user_id in user_history.keys():\n",
    "        cnt_dict[len(user_history[user_id])]+=1\n",
    "    print(cnt_dict)\n",
    "    \n",
    "def count_user_with_history_size_above(user_h, above):\n",
    "    cnt = 0\n",
    "    for user_id in user_history.keys():\n",
    "        if len(user_history[user_id]) >= above:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\n",
    "def filter_users(user_h, min_history_length, max_history_length=-1)->dict:\n",
    "    filtered_users = {}\n",
    "    count=0\n",
    "    for user, history in user_h.items():\n",
    "        if len(history) >= min_history_length:\n",
    "            filtered_users[user] = history[:max_history_length]\n",
    "            count+=1\n",
    "        \n",
    "        if count==-1:\n",
    "            break\n",
    "    return filtered_users\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b5f7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297\n"
     ]
    }
   ],
   "source": [
    "filtered_users = filter_users(user_history, 20, 50)\n",
    "print(len(filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9263e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "177b8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90d33587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 4669, Validation users: 1168, Test users: 1460\n"
     ]
    }
   ],
   "source": [
    "users = list(filtered_users.keys())\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train users into train (80%) and validation (20%) within the training set\n",
    "train_users, val_users = train_test_split(train_users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train, validation, and test data dictionaries\n",
    "train_data = {user: filtered_users[user] for user in train_users}\n",
    "val_data = {user: filtered_users[user] for user in val_users}\n",
    "test_data = {user: filtered_users[user] for user in test_users}\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train users: {len(train_users)}, Validation users: {len(val_users)}, Test users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e3ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "main_category_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2939bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_categories = [entry[\"main_category\"] for user in users for entry in filtered_users[user]]\n",
    "main_category_encoder.fit(main_categories)\n",
    "categories = [entry[\"categories\"] for user in users for entry in filtered_users[user]]\n",
    "category_encoder.fit(categories)\n",
    "product_ids = [entry[\"product_id\"] for user in users for entry in filtered_users[user]]\n",
    "product_encoder.fit(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ad48488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(histories):\n",
    "    all_ratings = [h[\"rating\"] for user in histories for h in histories[user]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit([[r] for r in all_ratings])\n",
    "    return scaler\n",
    "\n",
    "rating_scaler = normalize_ratings(filtered_users)\n",
    "\n",
    "def preprocess_history(history):\n",
    "    texts = [\n",
    "        f\"{h.get('review_title','')} {h.get('features','')} {h.get('main_category')}\" for h in history\n",
    "    ]\n",
    "    \n",
    "    texts = [text for text in texts if text.strip()]\n",
    "    \n",
    "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    ratings = torch.tensor([rating_scaler.transform([[h[\"rating\"]]])[0][0] for h in history], dtype=torch.float32)\n",
    "    \n",
    "    #categories = torch.tensor(category_encoder.transform([h[\"main_category\"] for h in history]))\n",
    "    \n",
    "    categories = torch.tensor(category_encoder.transform([h[\"categories\"] for h in history]))\n",
    "    \n",
    "    product_ids = torch.tensor(product_encoder.transform([h[\"product_id\"] for h in history]))\n",
    "    \n",
    "    return tokens, ratings, categories, product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5c45703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, category_encoder, product_encoder, seq_len=15, pred_len=5):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.category_encoder = category_encoder # Is it required?\n",
    "        self.product_encoder = product_encoder # Is it required?\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, history = list(self.data.items())[idx]\n",
    "        tokens, ratings, categories, product_ids = preprocess_history(history)\n",
    "        input_tokens = {\n",
    "            \"input_ids\":tokens[\"input_ids\"][:self.seq_len],\n",
    "            \"attention_mask\": tokens[\"attention_mask\"][:self.seq_len],\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"][:self.seq_len],\n",
    "        }\n",
    "        input_ratings = ratings[:self.seq_len]\n",
    "        input_categories = categories[:self.seq_len]\n",
    "        \n",
    "        future_products = product_ids[self.seq_len:]\n",
    "        target_vector = torch.zeros(len(self.product_encoder.classes_))\n",
    "        target_vector[future_products] = 1\n",
    "        \n",
    "        return input_tokens, input_ratings, input_categories, target_vector\n",
    "\n",
    "train_dataset = UserDataset(train_data, tokenizer, category_encoder, product_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84c5d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleVectorTransformerRecommendationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_categories=900, num_products=1000, d_model=128, nhead=8, num_encoder_layers=3):\n",
    "        super(SingleVectorTransformerRecommendationModel, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        self.category_embedding = nn.Embedding(num_categories, d_model)\n",
    "        \n",
    "        self.history_encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.history_encoder = nn.TransformerEncoder(self.history_encoder_layer, num_layers = num_encoder_layers)\n",
    "        \n",
    "        self.review_projection = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        \n",
    "        self.input_projection = nn.Linear(bert_hidden_size + d_model, d_model)\n",
    "\n",
    "        self.fc_out = nn.Linear(d_model, num_products)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        for layer in [self.fc_out, self.review_projection]:\n",
    "            nn.init.xavier_uniform_(layer.weight)\n",
    "            if layer.bias is not None:\n",
    "                nn.init.zeros_(layer.bias)\n",
    "        \n",
    "    \n",
    "    def forward(self, tokens, categories, compute_contrastive=False):\n",
    "        batch_size, seq_len, max_token_length = tokens[\"input_ids\"].shape\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"].view(-1, max_token_length)\n",
    "        attention_mask = tokens[\"attention_mask\"].view(-1, max_token_length)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].view(-1, max_token_length)\n",
    "        \n",
    "        bert_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "        \n",
    "        sequence_output = sequence_output[:,0,:].view(batch_size, seq_len, -1)\n",
    "#         print(sequence_output.shape)\n",
    "        category_embeds = self.category_embedding(categories)\n",
    "        \n",
    "#         print(category_embeds.shape)\n",
    "\n",
    "        combined_features = torch.cat([sequence_output, category_embeds], dim=-1)\n",
    "        combined_features = self.activation(combined_features)\n",
    "#         print(combined_features.shape)\n",
    "        projected_features = self.input_projection(combined_features)  # Shape: [batch_size, seq_len, d_model]\n",
    "        normalized_features = self.layer_norm(projected_features)  # Apply LayerNorm\n",
    "        activated_features = self.activation(normalized_features) \n",
    "\n",
    "        # Encode history with Transformer\n",
    "        history_encoded = self.history_encoder(activated_features)\n",
    "        \n",
    "        \n",
    "#         history_encoded = self.history_encoder(combined_features)\n",
    "        aggregated_features = history_encoded.mean(dim=1)\n",
    "        aggregated_features = self.layer_norm(aggregated_features)\n",
    "        \n",
    "        review_embeddings = self.activation(F.normalize(self.review_projection(history_encoded), p=2, dim=-1))\n",
    "#         review_embeddings = \n",
    "        \n",
    "        if compute_contrastive:\n",
    "            return review_embeddings\n",
    "        \n",
    "        logits = self.fc_out(self.activation(self.review_projection(aggregated_features)))\n",
    "        probabilities = self.sigmoid(logits)\n",
    "        \n",
    "        return probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d59fa52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleVectorTransformerRecommendationModel(num_categories=len(category_encoder.classes_), num_products=len(product_encoder.classes_)).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam([\n",
    "    {\"params\": model.bert.parameters(), \"lr\": 1e-5, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.category_embedding.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.input_projection.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.review_projection.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.history_encoder.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-5},\n",
    "    {\"params\": model.fc_out.parameters(), \"lr\": 1e-3, \"weight_decay\": 1e-5},\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f3f5b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_contrastive_loss(review_embeddings, ratings, margin=0.5):\n",
    "    \"\"\"\n",
    "    Compute contrastive loss based on review embeddings and ratings.\n",
    "    Args:\n",
    "        review_embeddings (Tensor): Encoded embeddings for each review [batch_size, seq_len, d_model].\n",
    "        ratings (Tensor): Normalized ratings for each review [batch_size, seq_len].\n",
    "        margin (float): Margin for contrastive separation.\n",
    "    Returns:\n",
    "        contrastive_loss (Tensor): Scalar loss value.\n",
    "    \"\"\"\n",
    "    # Compute similarity scores for each review embedding\n",
    "    \n",
    "\n",
    "    similarity_scores = torch.norm(review_embeddings, dim=-1)  # [batch_size, seq_len]\n",
    "#     print(\"Similarity Scores:\", similarity_scores.min().item(), similarity_scores.max().item())\n",
    "\n",
    "\n",
    "    # Positive loss: Align high-rating reviews\n",
    "    positive_loss = torch.mean((1 - similarity_scores) * ratings)\n",
    "\n",
    "    # Negative loss: Push away low-rating reviews\n",
    "    negative_loss = torch.mean(torch.clamp(similarity_scores - margin, min=0) * (1 - ratings))\n",
    "\n",
    "    # Combine positive and negative losses\n",
    "    contrastive_loss = positive_loss + negative_loss\n",
    "    return contrastive_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a75d017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute Top-K accuracy for multi-label classification.\n",
    "    Args:\n",
    "        predicted_vector (Tensor): Predicted probabilities for products [batch_size, num_products].\n",
    "        target_vector (Tensor): Binary target vector [batch_size, num_products].\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        top_k_accuracy (float): Top-K accuracy for the batch.\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch\n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "    # Gather the target values corresponding to the top-k predictions\n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "    # Count how many of the top-k predictions are correct\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Compute the accuracy as the mean of correct predictions\n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "\n",
    "    return top_k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9afe769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_metrics(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute top-k accuracy and precision for classification tasks.\n",
    "    \n",
    "    Args:\n",
    "        predicted_vector (torch.Tensor): Predicted probabilities or logits\n",
    "        target_vector (torch.Tensor): Ground truth labels\n",
    "        k (int, optional): Number of top predictions to consider. Defaults to 5.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing top-k accuracy and precision\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch \n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k] \n",
    " \n",
    "    # Gather the target values corresponding to the top-k predictions \n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k] \n",
    " \n",
    "    # Compute top-k accuracy\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size] \n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "    \n",
    "    # Compute top-k precision\n",
    "    # Precision = (number of correct predictions in top-k) / (total number of top-k predictions)\n",
    "    correct_predictions_count = true_positives.sum()\n",
    "    top_k_precision = correct_predictions_count / (top_k_preds.shape[0] * k)\n",
    "    \n",
    "    return top_k_accuracy,top_k_precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44e1565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_top_k_precision = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            target_vector = target_vector.to(device)\n",
    "            categories = categories.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector = model(tokens, categories, compute_contrastive=False)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc, top_k_prec = compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "\n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_top_k_precision += top_k_prec\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc,\n",
    "                                     \"Batch Top-K prec\": top_k_prec})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "    average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "    average_top_k_precision = total_top_k_precision / total_batches\n",
    "    print(f\"Average Top-{k} Precision: {average_top_k_precision:.4f}\")\n",
    "    return average_top_k_accuracy\n",
    "\n",
    "# Example usage:\n",
    "# average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "val_dataset = UserDataset(val_data, tokenizer, category_encoder, product_encoder)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8e52db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 584/584 [21:08<00:00,  2.17s/it, Product Loss=0.701, Contrastive Loss=0.174]\n",
      "Evaluating: 100%|██████████| 292/292 [02:56<00:00,  1.66it/s, Batch Top-K Acc=0]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.0942\n",
      "Epoch 1 Val result top k acc 0.09417808219178082\n",
      "Epoch 1/5\n",
      "  Avg Product Loss: 0.7179\n",
      "  Avg Contrastive Loss: 0.2064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 584/584 [21:24<00:00,  2.20s/it, Product Loss=0.7, Contrastive Loss=0.17]   \n",
      "Evaluating: 100%|██████████| 292/292 [02:43<00:00,  1.78it/s, Batch Top-K Acc=0.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1070\n",
      "Epoch 2 Val result top k acc 0.10702054794520548\n",
      "Epoch 2/5\n",
      "  Avg Product Loss: 0.7004\n",
      "  Avg Contrastive Loss: 0.1771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 584/584 [21:14<00:00,  2.18s/it, Product Loss=0.698, Contrastive Loss=0.168]\n",
      "Evaluating: 100%|██████████| 292/292 [02:45<00:00,  1.76it/s, Batch Top-K Acc=0]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1062\n",
      "Epoch 3 Val result top k acc 0.10616438356164383\n",
      "Epoch 3/5\n",
      "  Avg Product Loss: 0.6988\n",
      "  Avg Contrastive Loss: 0.1756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:   1%|          | 4/584 [00:10<25:50,  2.67s/it, Product Loss=0.698, Contrastive Loss=0.165]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/local/u1471428/2598669/ipykernel_1764940/497601338.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproduct_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcontrastive_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_product_loss = 0.0\n",
    "    total_contrastive_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
    "\n",
    "    for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "        tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "        ratings = ratings.to(device)\n",
    "        categories = categories.to(device)\n",
    "        target_vector = target_vector.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_vector = model(tokens, categories, compute_contrastive=False)\n",
    "        product_loss = loss_fn(predicted_vector, target_vector.float())\n",
    "        \n",
    "        review_embeddings = model(tokens, categories, compute_contrastive=True)\n",
    "        contrastive_loss = compute_contrastive_loss(review_embeddings, ratings)\n",
    "\n",
    "        # Compute loss\n",
    "        total_loss = product_loss + contrastive_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_product_loss += product_loss.item()\n",
    "        total_contrastive_loss += contrastive_loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"Product Loss\": product_loss.item(), \"Contrastive Loss\": contrastive_loss.item()})\n",
    "    \n",
    "    average_top_k = evaluate_top_k_accuracy(model, val_loader, k=5)\n",
    "    print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(f\"  Avg Product Loss: {total_product_loss / len(train_loader):.4f}\")\n",
    "    print(f\"  Avg Contrastive Loss: {total_contrastive_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "55e5024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'single_vector_contrastive.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"single_vector_contrastive.pth\")\n",
    "print(\"Model's state dictionary saved to 'single_vector_contrastive.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93e9c054",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_202544/1764966073.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"single_vector_contrastive.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"single_vector_contrastive.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1332cf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68c597a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:15<00:00,  1.87it/s, Batch Top-K Acc=0, Batch Top-K prec=0]      \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.1171\n",
      "Average Top-5 Precision: 0.0260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:14<00:00,  1.87it/s, Batch Top-K Acc=0, Batch Top-K prec=0]        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-3 Accuracy: 0.0911\n",
      "Average Top-3 Precision: 0.0333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:14<00:00,  1.87it/s, Batch Top-K Acc=0.25, Batch Top-K prec=0.25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.0397\n",
      "Average Top-1 Precision: 0.0397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=3)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=1)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e754214a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
