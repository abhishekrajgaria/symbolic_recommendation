{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e380ed2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/numpy-1.22.3-py3.10-linux-x86_64.egg (from transformers) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages (from requests->transformers) (2021.10.8)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/networkx-2.8.6-py3.10.egg (from torch) (2.8.6)\n",
      "Requirement already satisfied: jinja2 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/Jinja2-3.0.3-py3.10.egg (from torch) (3.0.3)\n",
      "Requirement already satisfied: fsspec in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy==1.13.1->torch) (1.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /uufs/chpc.utah.edu/sys/installdir/r8/python/3.10.3/lib/python3.10/site-packages/MarkupSafe-2.1.1-py3.10-linux-x86_64.egg (from jinja2->torch) (2.1.1)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: tqdm in /uufs/chpc.utah.edu/common/home/u1471428/.local/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4412b866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\r\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d996ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4b9f5498",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/user_history_full_data.json\" \n",
    "product_dict_filepath = \"/scratch/general/vast/u1471428/hugging_face_cache/product_dictionary.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1f2715bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(user_history_filepath, 'r')\n",
    "user_history = json.load(json_file)\n",
    "json_file.close()\n",
    "\n",
    "p_json_file = open(product_dict_filepath, 'r')\n",
    "product_dictionary = json.load(p_json_file)\n",
    "p_json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acef170b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B01C4319LO\n",
      "{'main_category': 'Baby', 'features': 'Aluminum, Imported, Convenient one-hand quick fold. Assembled Dimensions- 38 x 25.5 x 41.25 inches. Folded Dimensions- 13.5 x 25.5 x 33.25 inches. Product Weight- 18 pounds, Ultra-light weight aluminum frame, 3 wheel design allows for nimble steering and a sporty stance, Front wheel diameter 7 inches and rear wheel diameter 8.75 inches', 'description': 'Product Description, For ultimate convenience, the Chicco Viaro Quick-Fold Stroller has a sleek three-wheel design, lightweight aluminum frame, and one-hand quick fold. A pull-strap and button are conveniently tucked under the seat and easy to activate simultaneously for a compact, free-standing fold. The stroller is even easier to open again after closing.For infants, the Viaro Stroller functions as a travel system with easy click-in attachment for the KeyFit 30 Infant Car Seat. For older riders, the Viaro Stroller includes a detachable tray with two cup holders, adjustable canopy, and multi-position backrest. A swiveling front wheel and suspension help maintain a smooth ride from surface to surface. Toe-tap rear brakes keep the stroller in place when parked. For parents, the Viaro Stroller features a padded push-handle, parent tray with two cup holders, and a large basket that is easily accessible from the front or back.  The Viaro Travel System includes the #1-rated Chicco KeyFit 30 Infant Car Seat, which accommodates infants from 4 to 30 lbs and up to 30\". The KeyFit 30 is the easiest infant car seat to install simply, accurately, and securely every time.• Includes the #1-rated Chicco KeyFit 30 Infant Car Seat• Lightweight aluminum frame and sleek 3-wheel design• One-hand, free-standing fold • Multi-position reclining seat and adjustable canopy • Child tray with two cup holders• Parent tray with two cup holders • Swiveling front wheel with suspension for maneuverability • Toe-tap rear brakes for parking• Large storage basket with front and rear access• Padded handle, Brand Story, By Chicco', 'title': 'Chicco Viaro Travel System, Teak', 'categories': 's'}\n"
     ]
    }
   ],
   "source": [
    "for prod in product_dictionary.keys():\n",
    "    print(prod)\n",
    "    print(product_dictionary[prod])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45f6be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_user_with_history_sizes(user_h):\n",
    "    cnt_dict = defaultdict(int)\n",
    "    for user_id in user_history.keys():\n",
    "        cnt_dict[len(user_history[user_id])]+=1\n",
    "    print(cnt_dict)\n",
    "    \n",
    "def count_user_with_history_size_above(user_h, above):\n",
    "    cnt = 0\n",
    "    for user_id in user_history.keys():\n",
    "        if len(user_history[user_id]) >= above:\n",
    "            cnt+=1\n",
    "    print(cnt)\n",
    "\n",
    "def filter_users(user_h, min_history_length, max_history_length=-1)->dict:\n",
    "    filtered_users = {}\n",
    "    count=0\n",
    "    for user, history in user_h.items():\n",
    "        if len(history) >= min_history_length:\n",
    "            filtered_users[user] = history[:max_history_length]\n",
    "            count+=1\n",
    "        \n",
    "        if count==-1:\n",
    "            break\n",
    "    return filtered_users\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5f7559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7297\n"
     ]
    }
   ],
   "source": [
    "filtered_users = filter_users(user_history, 20, 50)\n",
    "print(len(filtered_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9263e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "177b8a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90d33587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train users: 4669, Validation users: 1168, Test users: 1460\n"
     ]
    }
   ],
   "source": [
    "users = list(filtered_users.keys())\n",
    "\n",
    "# Split into train (80%) and test (20%)\n",
    "train_users, test_users = train_test_split(users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train users into train (80%) and validation (20%) within the training set\n",
    "train_users, val_users = train_test_split(train_users, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train, validation, and test data dictionaries\n",
    "train_data = {user: filtered_users[user] for user in train_users}\n",
    "val_data = {user: filtered_users[user] for user in val_users}\n",
    "test_data = {user: filtered_users[user] for user in test_users}\n",
    "\n",
    "# Print dataset sizes for verification\n",
    "print(f\"Train users: {len(train_users)}, Validation users: {len(val_users)}, Test users: {len(test_users)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e3ab20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "main_category_encoder = LabelEncoder()\n",
    "category_encoder = LabelEncoder()\n",
    "product_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2939bc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_categories = [entry[\"main_category\"] for user in users for entry in filtered_users[user]]\n",
    "main_category_encoder.fit(main_categories)\n",
    "categories = [entry[\"categories\"] for user in users for entry in filtered_users[user]]\n",
    "category_encoder.fit(categories)\n",
    "product_ids = [entry[\"product_id\"] for user in users for entry in filtered_users[user]]\n",
    "product_encoder.fit(product_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ad48488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ratings(histories):\n",
    "    all_ratings = [h[\"rating\"] for user in histories for h in histories[user]]\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit([[r] for r in all_ratings])\n",
    "    return scaler\n",
    "\n",
    "rating_scaler = normalize_ratings(filtered_users)\n",
    "\n",
    "def preprocess_history(history):\n",
    "    texts = [\n",
    "        f\"{h.get('review_title','')} {h.get('features','')} {h.get('main_category')}\" for h in history\n",
    "    ]\n",
    "    \n",
    "    texts = [text for text in texts if text.strip()]\n",
    "    \n",
    "    tokens = tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    \n",
    "    ratings = torch.tensor([rating_scaler.transform([[h[\"rating\"]]])[0][0] for h in history], dtype=torch.float32)\n",
    "    \n",
    "    #categories = torch.tensor(category_encoder.transform([h[\"main_category\"] for h in history]))\n",
    "    \n",
    "    categories = torch.tensor(category_encoder.transform([h[\"categories\"] for h in history]))\n",
    "    \n",
    "    product_ids = torch.tensor(product_encoder.transform([h[\"product_id\"] for h in history]))\n",
    "    \n",
    "    return tokens, ratings, categories, product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c5c45703",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, category_encoder, product_encoder, seq_len=15, pred_len=5):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.category_encoder = category_encoder # Is it required?\n",
    "        self.product_encoder = product_encoder # Is it required?\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, history = list(self.data.items())[idx]\n",
    "        tokens, ratings, categories, product_ids = preprocess_history(history)\n",
    "        input_tokens = {\n",
    "            \"input_ids\":tokens[\"input_ids\"][:self.seq_len],\n",
    "            \"attention_mask\": tokens[\"attention_mask\"][:self.seq_len],\n",
    "            \"token_type_ids\": tokens[\"token_type_ids\"][:self.seq_len],\n",
    "        }\n",
    "        input_ratings = ratings[:self.seq_len]\n",
    "        input_categories = categories[:self.seq_len]\n",
    "        \n",
    "        future_products = product_ids[self.seq_len:]\n",
    "        target_vector = torch.zeros(len(self.product_encoder.classes_))\n",
    "        target_vector[future_products] = 1\n",
    "        \n",
    "        return input_tokens, input_ratings, input_categories, target_vector\n",
    "\n",
    "train_dataset = UserDataset(train_data, tokenizer, category_encoder, product_encoder)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84c5d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleVectorTransformerRecommendationModel(nn.Module):\n",
    "    def __init__(self, bert_model_name=\"bert-base-uncased\", num_categories=900, num_products=1000, d_model=128, nhead=8, num_encoder_layers=3):\n",
    "        super(SingleVectorTransformerRecommendationModel, self).__init__()\n",
    "        \n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        bert_hidden_size = self.bert.config.hidden_size\n",
    "        \n",
    "        self.category_embedding = nn.Embedding(num_categories, d_model)\n",
    "        \n",
    "        self.history_encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
    "        self.history_encoder = nn.TransformerEncoder(self.history_encoder_layer, num_layers = num_encoder_layers)\n",
    "        \n",
    "        self.input_projection = nn.Linear(bert_hidden_size + d_model, d_model)\n",
    "        \n",
    "        self.fc_out = nn.Linear(d_model, num_products)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.activation = nn.GELU()\n",
    "        self.init_weights()\n",
    "        \n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "    \n",
    "    def forward(self, tokens, ratings, categories):\n",
    "        batch_size, seq_len, max_token_length = tokens[\"input_ids\"].shape\n",
    "        \n",
    "        input_ids = tokens[\"input_ids\"].view(-1, max_token_length)\n",
    "        attention_mask = tokens[\"attention_mask\"].view(-1, max_token_length)\n",
    "        token_type_ids = tokens[\"token_type_ids\"].view(-1, max_token_length)\n",
    "        \n",
    "        bert_output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids\n",
    "        )\n",
    "        sequence_output = bert_output.last_hidden_state\n",
    "        \n",
    "        sequence_output = sequence_output[:,0,:].view(batch_size, seq_len, -1)\n",
    "        \n",
    "        category_embeds = self.category_embedding(categories)\n",
    "        combined_features = torch.cat([sequence_output, category_embeds], dim=-1)\n",
    "        \n",
    "        projected_features = self.input_projection(combined_features)  # Shape: [batch_size, seq_len, d_model]\n",
    "        normalized_features = self.layer_norm(projected_features)\n",
    "        activated_features = self.activation(normalized_features) \n",
    "\n",
    "        # Encode history with Transformer\n",
    "        history_encoded = self.history_encoder(activated_features)\n",
    "        \n",
    "        \n",
    "#         history_encoded = self.history_encoder(combined_features)\n",
    "        aggregated_features = history_encoded.mean(dim=1)\n",
    "        aggregated_features = self.layer_norm(aggregated_features)\n",
    "        \n",
    "        \n",
    "        logits = self.fc_out(aggregated_features)\n",
    "        probabilities = self.sigmoid(logits)\n",
    "        \n",
    "        return probabilities\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd179aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_accuracy(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute Top-K accuracy for multi-label classification.\n",
    "    Args:\n",
    "        predicted_vector (Tensor): Predicted probabilities for products [batch_size, num_products].\n",
    "        target_vector (Tensor): Binary target vector [batch_size, num_products].\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        top_k_accuracy (float): Top-K accuracy for the batch.\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch\n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "    # Gather the target values corresponding to the top-k predictions\n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "    # Count how many of the top-k predictions are correct\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "    # Compute the accuracy as the mean of correct predictions\n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "\n",
    "    return top_k_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fb150836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_top_k_metrics(predicted_vector, target_vector, k=5):\n",
    "    \"\"\"\n",
    "    Compute top-k accuracy and precision for classification tasks.\n",
    "    \n",
    "    Args:\n",
    "        predicted_vector (torch.Tensor): Predicted probabilities or logits\n",
    "        target_vector (torch.Tensor): Ground truth labels\n",
    "        k (int, optional): Number of top predictions to consider. Defaults to 5.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing top-k accuracy and precision\n",
    "    \"\"\"\n",
    "    # Get indices of the top-k predictions for each batch \n",
    "    top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k] \n",
    " \n",
    "    # Gather the target values corresponding to the top-k predictions \n",
    "    true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k] \n",
    " \n",
    "    # Compute top-k accuracy\n",
    "    top_k_correct = true_positives.sum(dim=-1)  # [batch_size] \n",
    "    top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "    \n",
    "    # Compute top-k precision\n",
    "    # Precision = (number of correct predictions in top-k) / (total number of top-k predictions)\n",
    "    correct_predictions_count = true_positives.sum()\n",
    "    top_k_precision = correct_predictions_count / (top_k_preds.shape[0] * k)\n",
    "    \n",
    "    return top_k_accuracy,top_k_precision.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a69b0ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def evaluate_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_top_k_precision = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            ratings = ratings.to(device)\n",
    "            categories = categories.to(device)\n",
    "            target_vector = target_vector.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc = compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "\n",
    "            top_k_acc, top_k_prec= compute_top_k_metrics(predicted_vector, target_vector, k=k)\n",
    "\n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_top_k_precision += top_k_prec\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc,\n",
    "                                     \"Batch Top-K prec\": top_k_prec})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "    average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "    print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "    average_top_k_precision = total_top_k_precision / total_batches\n",
    "    print(f\"Average Top-{k} Precision: {average_top_k_precision:.4f}\")\n",
    "    return average_top_k_accuracy\n",
    "\n",
    "# Example usage:\n",
    "# average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "val_dataset = UserDataset(val_data, tokenizer, category_encoder, product_encoder)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d59fa52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleVectorTransformerRecommendationModel(num_categories=len(category_encoder.classes_), num_products=len(product_encoder.classes_)).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f8e52db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 584/584 [15:01<00:00,  1.54s/it, Loss=0.703]\n",
      "Evaluating: 100%|██████████| 292/292 [02:43<00:00,  1.78it/s, Batch Top-K Acc=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.0000\n",
      "Epoch 1 Val result top k acc 0.0\n",
      "Epoch 1/2, Average Loss: 0.7561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 584/584 [15:03<00:00,  1.55s/it, Loss=0.696]\n",
      "Evaluating: 100%|██████████| 292/292 [02:41<00:00,  1.80it/s, Batch Top-K Acc=0]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-5 Accuracy: 0.0043\n",
      "Epoch 2 Val result top k acc 0.004280821917808219\n",
      "Epoch 2/2, Average Loss: 0.6986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\", leave=True)\n",
    "\n",
    "    for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "        tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "        ratings = ratings.to(device)\n",
    "        categories = categories.to(device)\n",
    "        target_vector = target_vector.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = loss_fn(predicted_vector, target_vector.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\"Loss\": loss.item()})\n",
    "    \n",
    "    average_top_k = evaluate_top_k_accuracy(model, val_loader, k=5)\n",
    "    print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Average Loss: {total_loss / len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be451566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1332cf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state dictionary saved to 'single_vector_baseline.pth'\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"single_vector_baseline.pth\")\n",
    "print(\"Model's state dictionary saved to 'single_vector_baseline.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f58c6681",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_200977/4188175659.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"single_vector_baseline.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"single_vector_baseline.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b40c32bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u1471428/2606234/ipykernel_200977/4188175659.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"single_vector_baseline.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"single_vector_baseline.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "68c597a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "911ad22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:18<00:00,  1.84it/s, Batch Top-K Acc=0, Batch Top-K prec=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-3 Accuracy: 0.0000\n",
      "Average Top-3 Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 365/365 [03:18<00:00,  1.84it/s, Batch Top-K Acc=0, Batch Top-K prec=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Top-1 Accuracy: 0.0000\n",
      "Average Top-1 Precision: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# average_top_k = evaluate_top_k_accuracy(model, test_loader, k=5)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=3)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")\n",
    "average_top_k = evaluate_top_k_accuracy(model, test_loader, k=1)\n",
    "# print(f\"Epoch {epoch+1} Val result top k acc {average_top_k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "484c589c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ana_top_k_accuracy(model, test_loader, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate average Top-K accuracy over the test set with a progress bar.\n",
    "    Args:\n",
    "        model (nn.Module): Trained model to evaluate.\n",
    "        test_loader (DataLoader): DataLoader for the test dataset.\n",
    "        k (int): Number of top predictions to consider.\n",
    "    Returns:\n",
    "        average_top_k_accuracy (float): Average Top-K accuracy over all test batches.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_top_k_accuracy = 0.0\n",
    "    total_batches = 0\n",
    "\n",
    "    # Add a progress bar\n",
    "    progress_bar = tqdm(test_loader, desc=\"Evaluating\", leave=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, ratings, categories, target_vector in progress_bar:\n",
    "            # Move inputs and targets to the device\n",
    "            tokens = {key: val.to(device) for key, val in batch_tokens.items()}\n",
    "            ratings = ratings.to(device)\n",
    "            categories = categories.to(device)\n",
    "            target_vector = target_vector.to(device)\n",
    "\n",
    "            # Make predictions\n",
    "            predicted_vector = model(tokens, ratings, categories)\n",
    "\n",
    "            # Compute Top-K accuracy for the batch\n",
    "            top_k_acc = compute_top_k_accuracy(predicted_vector, target_vector, k=k)\n",
    "            \n",
    "            top_k_preds = torch.topk(predicted_vector, k=k, dim=-1).indices  # [batch_size, k]\n",
    "\n",
    "            # Gather the target values corresponding to the top-k predictions\n",
    "            true_positives = target_vector.gather(1, top_k_preds)  # [batch_size, k]\n",
    "\n",
    "            # Count how many of the top-k predictions are correct\n",
    "            top_k_correct = true_positives.sum(dim=-1)  # [batch_size]\n",
    "\n",
    "            # Compute the accuracy as the mean of correct predictions\n",
    "            top_k_accuracy = (top_k_correct > 0).float().mean().item()\n",
    "            \n",
    "            if top_k_accuracy==0:\n",
    "                to_print = analyze_predictions_and_targets(top_k_preds, target_vector)\n",
    "                print(json.dumps(to_print, indent=2))\n",
    "                break\n",
    "                \n",
    "            # Update total accuracy and batch count\n",
    "            total_top_k_accuracy += top_k_acc\n",
    "            total_batches += 1\n",
    "\n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\"Batch Top-K Acc\": top_k_acc})\n",
    "\n",
    "    # Compute average Top-K accuracy\n",
    "#     average_top_k_accuracy = total_top_k_accuracy / total_batches\n",
    "#     print(f\"Average Top-{k} Accuracy: {average_top_k_accuracy:.4f}\")\n",
    "#     return average_top_k_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f02faca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def analyze_predictions_and_targets(top_k_preds, target_vector):\n",
    "    \"\"\"\n",
    "    Analyze predictions to determine which items are in predictions but not in targets,\n",
    "    which are in both predictions and targets, and which are in the target vector.\n",
    "\n",
    "    Args:\n",
    "        top_k_preds (Tensor): Indices of top-K predicted products [batch_size, k].\n",
    "        target_vector (Tensor): Binary target vector for products [batch_size, num_products].\n",
    "        product_encoder (LabelEncoder): Encoder to map product indices to product IDs.\n",
    "        product_dictionary (dict): Dictionary containing product details (title, rating, etc.).\n",
    "\n",
    "    Returns:\n",
    "        result (list of dict): Contains information about items in `top_k_preds` but not in `target_vector`,\n",
    "                               items in both `top_k_preds` and `target_vector`,\n",
    "                               and items in `target_vector`.\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    # Convert product indices to product IDs\n",
    "    product_indices = torch.arange(target_vector.size(-1))  # [num_products]\n",
    "    product_ids = product_encoder.inverse_transform(product_indices.cpu().numpy())  # Decode all product IDs\n",
    "    \n",
    "    for batch_idx in range(top_k_preds.size(0)):\n",
    "        preds = top_k_preds[batch_idx].cpu().numpy()  # Predicted indices\n",
    "        targets = torch.where(target_vector[batch_idx] > 0)[0].cpu().numpy()  # Target indices\n",
    "        \n",
    "        preds_product_ids = [product_ids[i] for i in preds]  # Get product IDs for predictions\n",
    "        targets_product_ids = [product_ids[i] for i in targets]  # Get product IDs for targets\n",
    "        \n",
    "        # Products in predictions but not in targets\n",
    "        preds_not_in_targets = list(set(preds_product_ids) - set(targets_product_ids))\n",
    "        \n",
    "        # Products in both predictions and targets\n",
    "        preds_in_targets = list(set(preds_product_ids) & set(targets_product_ids))\n",
    "        \n",
    "        # Products only in the target vector\n",
    "        target_only = list(set(targets_product_ids))\n",
    "        \n",
    "        # Fetch details from the product dictionary\n",
    "        items_not_in_targets = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in preds_not_in_targets\n",
    "        ]\n",
    "        \n",
    "        items_in_targets = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in preds_in_targets\n",
    "        ]\n",
    "        \n",
    "        items_in_target_vector = [\n",
    "            {\n",
    "                \"product_id\": pid,\n",
    "                \"title\": product_dictionary.get(pid, {}).get(\"title\", \"Unknown\"),\n",
    "                \"rating\": product_dictionary.get(pid, {}).get(\"average_rating\", \"Unknown\"),\n",
    "            }\n",
    "            for pid in target_only\n",
    "        ]\n",
    "        \n",
    "        result.append(\n",
    "            {\n",
    "                \"batch_index\": batch_idx,\n",
    "                \"not_in_targets\": items_not_in_targets,\n",
    "                \"in_targets\": items_in_targets,\n",
    "                \"in_target_vector\": items_in_target_vector,\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "\n",
    "def print_results_as_json(results):\n",
    "    \"\"\"\n",
    "    Print results in JSON format with indent=2.\n",
    "    Args:\n",
    "        results (list of dict): The result of analyze_predictions_and_targets.\n",
    "    \"\"\"\n",
    "    print(json.dumps(results, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0c2ffc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = UserDataset(test_data, tokenizer, category_encoder, product_encoder)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b40d2c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  93%|█████████▎| 1365/1460 [03:15<00:13,  6.99it/s, Batch Top-K Acc=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"batch_index\": 0,\n",
      "    \"not_in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B07DHVWP9B\",\n",
      "        \"title\": \"Smilo On-The-Go Snack Containers, Leak-Resistant, BPA-Free, 3 Count\",\n",
      "        \"rating\": 3.9\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BVV1ZD5C\",\n",
      "        \"title\": \"Tommee Tippee Breast-Like Pacifier, Skin-Like Texture, Symmetrical Design, BPA-Free Binkies, 6-18m, 4-Count\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07BPSX1KH\",\n",
      "        \"title\": \"Colgate Mattress zenBaby Hybrid 2-N-1 - Dual-Firmness Transition Crib Mattress Featuring Supportive Ecofoam and Microcoils with KulKote Technology and Ultra-Soft Cover\",\n",
      "        \"rating\": 3.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B007SZKG04\",\n",
      "        \"title\": \"Kyle and Deena light yellow baby blanket with daisy print 30\\\" by 34\\\"\",\n",
      "        \"rating\": 5.0\n",
      "      }\n",
      "    ],\n",
      "    \"in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B00PF841GQ\",\n",
      "        \"title\": \"Philips AVENT Breast Milk Storage Cups And Lids, 10 6oz Containers, SCF618/10\",\n",
      "        \"rating\": 4.5\n",
      "      }\n",
      "    ],\n",
      "    \"in_target_vector\": [\n",
      "      {\n",
      "        \"product_id\": \"B098WYMWVJ\",\n",
      "        \"title\": \"Andy Pandy Bamboo Disposable Diapers, Large, White, 20-31 lbs, 26 Count\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01DFWNJJI\",\n",
      "        \"title\": \"EPAuto Baby Car Back Seat Mirror for Baby and Mom Rear Facing View, Wide Convex Shatterproof Glass and Fully Assembled Crash Tested\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0C5B1WSGJ\",\n",
      "        \"title\": \"Infantino Flip Advanced 4-in-1 Carrier - Ergonomic, convertible, face-in and face-out front and back carry for newborns and older babies 8-32 lbs\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B09C2DS9ZB\",\n",
      "        \"title\": \"Burt's Bees Baby 100% Natural Origin Diaper Rash Ointment - 3 Ounces Tube\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01LZPAXQR\",\n",
      "        \"title\": \"Woolino Newborn Swaddle Blanket, 100% Superfine Merino Wool, for Babies 0-3 Months, Blue\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00ADZ8JQE\",\n",
      "        \"title\": \"SHOO-FOO - Bamboo Baby Blanket - Pure Silk Border (30 x 40 in.)\",\n",
      "        \"rating\": 3.3\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01970FPLC\",\n",
      "        \"title\": \"4 COUNT!!! - Bamboo Muslin Receiving Swaddle Baby Blankets Luxuriously Soft!\",\n",
      "        \"rating\": 3.9\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B084KX7WKC\",\n",
      "        \"title\": \"Dr. Browns Natural Flow Preemie Standard Nipple pack of 4\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01AUVAW9W\",\n",
      "        \"title\": \"Antipodes Merino Baby Stroller Swaddle Blanket 100% Wool, Stretchy, Large (Aqua)\",\n",
      "        \"rating\": 3.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00L4HUH56\",\n",
      "        \"title\": \"Rumina Hands Free Classic Pump&Nurse Adjustable Nursing Bra for Pumping. Ideal for Breastfeeding Pumps by Spectra, Medela, Lansinoh, etc, White L\",\n",
      "        \"rating\": 4.1\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00GVFF16Q\",\n",
      "        \"title\": \"Comotomo 5 oz and 8 oz Baby Bottles, 4 Pack\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00PF841GQ\",\n",
      "        \"title\": \"Philips AVENT Breast Milk Storage Cups And Lids, 10 6oz Containers, SCF618/10\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0B6Q19FDY\",\n",
      "        \"title\": \"Dr. Brown\\u2019s Natural Flow\\u00ae Anti-Colic Newborn Baby Bottle Gift Set\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00E953IDI\",\n",
      "        \"title\": \"Summer Complete Nursery Care Kit, Pink/White\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B017ORW0ZO\",\n",
      "        \"title\": \"Boppy Luxe Nursing Pillow and Positioner, Elephant Snuggle Taupe, Ultra-soft minky fabric on one side with adorable appliqu\\u00e9 and coordinating piping\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0045VA3SO\",\n",
      "        \"title\": \"Summer Snuzzler Infant Support for Car Seats and Strollers, Ivory\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B017LJLI9Y\",\n",
      "        \"title\": \"MommyDaddy&Me Diaper Bag Insert Organizer, Black\",\n",
      "        \"rating\": 4.3\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B01942P6MG\",\n",
      "        \"title\": \"Era Organics Baby Diaper Balm - Extra Soothing and Nourishing USDA Organic Diaper Cream for Dry, Sensitive Skin. All Natural Baby Balm to Help Excess Moisture, Rash and Chafing Baby Ointment\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B001I2DNV2\",\n",
      "        \"title\": \"Nature's Baby Organics Shampoo & Body Wash, Lavender Chamomile, 16 oz | Babies, Kids, & Adults! Moisturizing, Soft, Gentle, Rich, Hypoallergenic | No Harsh Chemicals, Parabens, SLS, Glutens\",\n",
      "        \"rating\": 4.0\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00WIT9J9O\",\n",
      "        \"title\": \"Angel Dear Bamboo Swaddle Blanket, Kitty Ballerina\",\n",
      "        \"rating\": 4.5\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ana_top_k_accuracy(model, test_loader, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "258abae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1460 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"batch_index\": 0,\n",
      "    \"not_in_targets\": [\n",
      "      {\n",
      "        \"product_id\": \"B07BPSX1KH\",\n",
      "        \"title\": \"Colgate Mattress zenBaby Hybrid 2-N-1 - Dual-Firmness Transition Crib Mattress Featuring Supportive Ecofoam and Microcoils with KulKote Technology and Ultra-Soft Cover\",\n",
      "        \"rating\": 3.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00PF841GQ\",\n",
      "        \"title\": \"Philips AVENT Breast Milk Storage Cups And Lids, 10 6oz Containers, SCF618/10\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07DHVWP9B\",\n",
      "        \"title\": \"Smilo On-The-Go Snack Containers, Leak-Resistant, BPA-Free, 3 Count\",\n",
      "        \"rating\": 3.9\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BVV1ZD5C\",\n",
      "        \"title\": \"Tommee Tippee Breast-Like Pacifier, Skin-Like Texture, Symmetrical Design, BPA-Free Binkies, 6-18m, 4-Count\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B007SZKG04\",\n",
      "        \"title\": \"Kyle and Deena light yellow baby blanket with daisy print 30\\\" by 34\\\"\",\n",
      "        \"rating\": 5.0\n",
      "      }\n",
      "    ],\n",
      "    \"in_targets\": [],\n",
      "    \"in_target_vector\": [\n",
      "      {\n",
      "        \"product_id\": \"B09VQJ3FLS\",\n",
      "        \"title\": \"Bright Starts MICKEY MOUSE Comfy Disney Baby Bouncer in Cloudscapes Includes -Toy Bar with 3 Cute Toys, Plays 7 Soothing Melodies w/Auto Shut-Off, Age 0-6 Months\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0013P53YE\",\n",
      "        \"title\": \"Dr. Brown's Standard Dishwashing Basket\",\n",
      "        \"rating\": 3.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0B6Q19FDY\",\n",
      "        \"title\": \"Dr. Brown\\u2019s Natural Flow\\u00ae Anti-Colic Newborn Baby Bottle Gift Set\",\n",
      "        \"rating\": 4.7\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B07TSG87YD\",\n",
      "        \"title\": \"HUGGIES Snug & Dry Diapers, Size 5, 96 Count, GIGA JR PACK (Packaging May Vary)\",\n",
      "        \"rating\": 4.6\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00H8MR88A\",\n",
      "        \"title\": \"Graco FastAction Fold Stroller Click Connect Travel System, Nyssa (Discontinued by Manufacturer)\",\n",
      "        \"rating\": 4.4\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00HV5W1TA\",\n",
      "        \"title\": \"Disney Baby Care Center Play Yard, My Hunny Stripe\",\n",
      "        \"rating\": 4.0\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B00422MQHM\",\n",
      "        \"title\": \"RoomMates RMK1502SLM Winnie The Pooh 100 Aker Wood Map Peel and Stick Wall Decal\",\n",
      "        \"rating\": 4.8\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B0BWYDBGSH\",\n",
      "        \"title\": \"[Upgraded] 4 Packs Extreme Resistance 3977393 Dryer Thermal Fuse Replacement by BlueStars - Exact Fit For Whirlpool & Kenmore Dryers - Replaces AP3094244 3399848 AH334299 279816VP\",\n",
      "        \"rating\": 4.5\n",
      "      },\n",
      "      {\n",
      "        \"product_id\": \"B000056OUO\",\n",
      "        \"title\": \"Prince Lionheart Hanging Diaper Depot Wipes Warmer Storage Depot Nursery Essentials Baby Registry\",\n",
      "        \"rating\": 4.5\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ana_top_k_accuracy(model, test_loader, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd69d79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
